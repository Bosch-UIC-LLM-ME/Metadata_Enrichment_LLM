{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e04f1e",
   "metadata": {},
   "source": [
    "## Setting Up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40684e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c079a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"{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}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0008b4d5",
   "metadata": {},
   "source": [
    "## 1. Loading PDFs and chunking with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d70866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f15c939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This basic example demostrate the LLM response and ChatModel Response\n",
    "\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#app.py\n",
    "\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e3c4330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None Azure https://testopenaisaturday.openai.azure.com/ 2023-10-01-preview\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from the .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Retrieve Azure OpenAI specific configuration from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "OPENAI_API_TYPE = \"Azure\"\n",
    "OPENAI_API_BASE = \"https://testopenaisaturday.openai.azure.com/\"\n",
    "OPENAI_API_VERSION = \"2023-10-01-preview\"\n",
    "\n",
    "print(OPENAI_API_KEY, OPENAI_API_TYPE,OPENAI_API_BASE, OPENAI_API_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04135f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI library configuration using the retrieved environment variables\n",
    "openai.api_type = \"Azure\"\n",
    "openai.api_base = \"https://testopenaisaturday.openai.azure.com/\"\n",
    "openai.api_version = \"2023-10-01-preview\"\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ff4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#app.py\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from dotenv import find_dotenv, load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "197ddc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pydantic 2.9.2\n",
      "Uninstalling pydantic-2.9.2:\n",
      "  Successfully uninstalled pydantic-2.9.2\n",
      "Found existing installation: dataclasses-json 0.6.7\n",
      "Uninstalling dataclasses-json-0.6.7:\n",
      "  Successfully uninstalled dataclasses-json-0.6.7\n",
      "Found existing installation: joblib 1.1.1\n",
      "Uninstalling joblib-1.1.1:\n",
      "  Successfully uninstalled joblib-1.1.1\n",
      "Found existing installation: langchain 0.3.7\n",
      "Uninstalling langchain-0.3.7:\n",
      "  Successfully uninstalled langchain-0.3.7\n",
      "Found existing installation: unstructured-client 0.27.0\n",
      "Uninstalling unstructured-client-0.27.0:\n",
      "  Successfully uninstalled unstructured-client-0.27.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pydantic dataclasses-json joblib langchain unstructured-client -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8ae940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic<2,>=1\n",
      "  Using cached pydantic-1.10.19-cp311-cp311-macosx_11_0_arm64.whl.metadata (152 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<2,>=1) (4.12.2)\n",
      "Using cached pydantic-1.10.19-cp311-cp311-macosx_11_0_arm64.whl (2.3 MB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.9.2\n",
      "    Uninstalling pydantic-2.9.2:\n",
      "      Successfully uninstalled pydantic-2.9.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.3.15 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.19 which is incompatible.\n",
      "pydantic-settings 2.6.1 requires pydantic>=2.7.0, but you have pydantic 1.10.19 which is incompatible.\n",
      "unstructured-client 0.27.0 requires pydantic<2.10.0,>=2.9.2, but you have pydantic 1.10.19 which is incompatible.\n",
      "chainlit 1.3.1 requires numpy<2.0,>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
      "langchain 0.3.7 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.19 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.19\n",
      "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (0.6.7)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.7.0,>=0.6.7) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7.0,>=0.6.7) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7) (4.12.2)\n",
      "Requirement already satisfied: joblib~=1.1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (0.1.139)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (1.24.3)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain<0.4.0,>=0.3.6)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain<0.4.0,>=0.3.6) (8.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.6) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.6) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.6) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.6) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.4.0,>=0.3.6) (1.8.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain<0.4.0,>=0.3.6) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain<0.4.0,>=0.3.6) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain<0.4.0,>=0.3.6) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.6) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.6) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.6) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.6) (2023.7.22)\n",
      "Requirement already satisfied: anyio in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.4.0,>=0.3.6) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain<0.4.0,>=0.3.6) (2.1)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.19\n",
      "    Uninstalling pydantic-1.10.19:\n",
      "      Successfully uninstalled pydantic-1.10.19\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chainlit 1.3.1 requires numpy<2.0,>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-2.9.2\n",
      "Requirement already satisfied: unstructured in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (0.16.4)\n",
      "Requirement already satisfied: unstructured-client in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (0.27.0)\n",
      "Requirement already satisfied: chardet in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (4.9.2)\n",
      "Requirement already satisfied: nltk in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: requests in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (2.14.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (2024.10.22)\n",
      "Requirement already satisfied: langdetect in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (1.24.3)\n",
      "Requirement already satisfied: rapidfuzz in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (3.10.1)\n",
      "Requirement already satisfied: backoff in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: wrapt in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: tqdm in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (4.65.0)\n",
      "Requirement already satisfied: psutil in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (5.9.0)\n",
      "Requirement already satisfied: python-oxmsg in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: html5lib in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: cryptography>=3.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (41.0.2)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (0.2.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (0.27.2)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (1.0.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (2.9.2)\n",
      "Requirement already satisfied: pypdf>=4.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (1.0.0)\n",
      "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from unstructured-client) (0.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from python-dateutil==2.8.2->unstructured-client) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from cryptography>=3.1->unstructured-client) (1.15.1)\n",
      "Requirement already satisfied: anyio in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client) (3.5.0)\n",
      "Requirement already satisfied: certifi in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client) (1.0.6)\n",
      "Requirement already satisfied: idna in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx>=0.27.0->unstructured-client) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from typing-inspect<0.10.0,>=0.9.0->unstructured-client) (0.4.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from beautifulsoup4->unstructured) (2.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from dataclasses-json->unstructured) (3.23.1)\n",
      "Requirement already satisfied: webencodings in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (1.1.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: olefile in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: pycparser in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.21)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n"
     ]
    }
   ],
   "source": [
    "# Install compatible versions\n",
    "!pip install \"pydantic<2,>=1\"\n",
    "!pip install \"dataclasses-json<0.7.0,>=0.6.7\"\n",
    "!pip install \"joblib~=1.1.0\"\n",
    "!pip install \"langchain<0.4.0,>=0.3.6\"\n",
    "!pip install unstructured unstructured-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7fc9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_unstructured.unit_utils import assert_round_trips_through_JSON, example_doc_path\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from unstructured.documents.elements import ElementType\n",
    "\n",
    "#!pip install unstructured_inference\n",
    "#!pip install -U langchain-unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676082cf",
   "metadata": {},
   "source": [
    "## PINECONE Initialising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94cb7d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-pinecone pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b463c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PINECONE API.     1203aeba-36cc-4ede-9dc6-1f01153fbde8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d220a6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Pinecone API key: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "if not os.getenv(\"PINECONE_API_KEY\"):\n",
    "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2118f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pinecone API key - pcsk_wpzoJ_CXs3QWXo2Q6BGnx84d4kyRVn7kDw5N9SvCEJXEWNehAafEiWvtHoW9X2qLdRThh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c3b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Old key(rkesh@uic.edu)Openai API key - \n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ad12914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"langchain-test-index\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=3072,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f314f2",
   "metadata": {},
   "source": [
    "## Open AI Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232aaddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_openai in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain_openai) (0.3.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain_openai) (1.54.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.65.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.16)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6245c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os  # Import os module\n",
    "\n",
    "# Set the OpenAI API key using getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Instantiate OpenAI embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Openai API key (gkramyashree@gmail.com):\n",
    "#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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "637bf89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (5.0.1)\r\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (2023.7.22)\r\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (1.1.0)\r\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (0.0.7)\r\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (4.12.2)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from pinecone-client) (1.26.16)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b6f54ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/0cvsl7fj6nzdpcfzc69z4gz00000gn/T/ipykernel_73564/3643445054.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d9391",
   "metadata": {},
   "source": [
    "## Text CHUNKING (semantic Chunking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94d09f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587a7c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73e04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f1c120a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 218\n",
      "Chunk 1:\n",
      "User Guide\n",
      "Amazon S3 on Outposts\n",
      "API Version 2006-03-01\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide\n",
      "Amazon S3 on Outposts: User Guide\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n",
      "Amazon's trademarks and trade dress may not be used in connection with any product or service \n",
      "that is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \n",
      "manner that dis\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Version ID..................................................................................................................................................4\n",
      "Storage class and encryption...............................................................................................................4\n",
      "Bucket policy............................................................................................................................................4\n",
      "S3 on Outposts access points..................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 3:\n",
      "AWS SDKs.................................................................................................................................................8\n",
      "Paying for S3 on Outposts.........................................................................................................................8\n",
      "Next steps......................................................................................................................................................8\n",
      "Setting up your Outpost............\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document  # Import the Document class\n",
    "\n",
    "# Step 1: Extract text from the PDF using PyPDF2\n",
    "with open('s3-outposts.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    \n",
    "\n",
    "    # Iterate through all the pages and extract text\n",
    "    text = ''\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:  # Ensure the text extraction is successful\n",
    "            text += extracted_text\n",
    "\n",
    "# Step 2: Create a Document object\n",
    "document = Document(page_content=text)\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 3: Use RecursiveCharacterTextSplitter for better splitting\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \"]\n",
    ")\n",
    "\n",
    "# Split the document text into smaller chunks\n",
    "texts = text_splitter.split_documents([document])  # Pass in a list of Document objects\n",
    "\n",
    "# Step 4: Print the number of chunks\n",
    "print(f\"Number of chunks: {len(texts)}\")\n",
    "\n",
    "# Step 5: Optionally, output the first few chunks to inspect the splitting\n",
    "for i, chunk in enumerate(texts[:3]):  # Limit to first 3 chunks for display\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk.page_content[:500])  # Print first 500 characters of the chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ddcfb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "•AWS managed policies for Amazon S3 on Outposts\n",
      "•Using service-linked roles for Amazon S3 on Outposts\n",
      "Setting up IAM with S3 on Outposts\n",
      "AWS Identity and Access Management (IAM) is an AWS service that helps an administrator securely \n",
      "control access to AWS resources. IAM administrators control who can be authenticated (signed in) \n",
      "Setting up IAM API Version 2006-03-01 113Amazon S3 on Outposts User Guide\n",
      "and authorized (have permissions) to use Amazon S3 on Outposts resources. IAM is an AWS servic\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "the S3 on Outposts resource.\n",
      "•A bucket policy is attached to the bucket and allows or denies requests to the bucket and the \n",
      "objects in it based on the elements in the policy.\n",
      "•In contrast, an access point policy is attached to the access point and allows or denies requests to \n",
      "the access point.\n",
      "The access point policy works with the bucket policy that is attached to the underlying S3 on \n",
      "Outposts bucket. For an application or user to access objects in an S3 on Outposts bucket through \n",
      "an S3 on \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Output only the first 2-3 split text chunks with truncation to avoid large data output\n",
    "for chunk in texts[125:127]:  # Display the first 3 chunks\n",
    "    print(chunk.page_content[:500])  # Print only the first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf1184",
   "metadata": {},
   "source": [
    "## Semantic Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada4f17",
   "metadata": {},
   "source": [
    "1. Install Necessary Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b90d67d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (1.2.0)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: scipy in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (1.9.3)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.9.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Collecting numpy>=1.17.3 (from scikit-learn)\n",
      "  Downloading numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: sympy in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.3.0-py3-none-any.whl (268 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading numpy-1.25.2-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.20.3-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, numpy, fsspec, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 1.25.2 which is incompatible.\n",
      "chainlit 1.3.1 requires numpy<2.0,>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.10.0 huggingface-hub-0.26.2 numpy-1.25.2 safetensors-0.4.5 sentence-transformers-3.3.0 tokenizers-0.20.3 transformers-4.46.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc89c66",
   "metadata": {},
   "source": [
    "## Revised Code for Semantic Chunking (for further improving the chunking better) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45da4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.0.2\n",
      "Uninstalling numpy-2.0.2:\n",
      "  Successfully uninstalled numpy-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dad650b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.24.3\n",
      "  Using cached numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.3-cp311-cp311-macosx_11_0_arm64.whl (13.8 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "faiss-cpu 1.9.0 requires numpy<3.0,>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
      "chainlit 1.3.1 requires numpy<2.0,>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.24.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f281efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.2.0\n",
      "Uninstalling scikit-learn-1.2.0:\n",
      "  Successfully uninstalled scikit-learn-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall scikit-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af69dd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn) (3.5.0)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2 scikit-learn-1.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb37a42",
   "metadata": {},
   "source": [
    "1. Extract Text and Split into Paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb6ec133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Extract text from PDF using PyPDF2\n",
    "with open('s3-outposts.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:  # Ensure text extraction was successful\n",
    "            text += extracted_text\n",
    "\n",
    "# Split text into paragraphs (using a simple heuristic here; you could use more advanced tools like spaCy)\n",
    "paragraphs = [p.strip() for p in text.split('\\n') if p.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33a945",
   "metadata": {},
   "source": [
    "2. Generate Paragraph Embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e60734cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for each paragraph\n",
    "paragraph_embeddings = model.encode(paragraphs)  # Removed convert_to_tensor=True to keep it as a NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dd30c1",
   "metadata": {},
   "source": [
    "3. Proceed with Clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f5166f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "User Guide •Next steps Next steps •Next steps Next steps Prerequisites •Conﬁgurations overview Sample conﬁguration settings \"Configurations\": [ \"Configurations\": [ Conﬁgurations overview see Prerequisites. Guide . Step 6 . found in Step 2 . Step 1 . conﬁguration: Interface User Guide. conﬁguration. Prerequisites User Guide . Guide . information about how to information about how to User Guide . User Guide .\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Amazon S3 on Outposts Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide Amazon S3 on Outposts: User Guide Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved. sponsored by Amazon.Amazon S3 on Outposts User Guide What is S3 on Outposts? .................................................................................................................1 How S3 on Outposts works..........................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 3:\n",
      "API Version 2006-03-01 Related services............................................................................................................................................7 Supported API operations........................................................................................................................12 Other services...........................................................................................................................................184 •Related servic\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Compute Cosine Distance Matrix\n",
    "cosine_sim_matrix = cosine_similarity(paragraph_embeddings)\n",
    "cosine_dist_matrix = 1 - cosine_sim_matrix  # Cosine distance is (1 - cosine similarity)\n",
    "\n",
    "# Cluster Paragraphs with Adjusted Parameters using Cosine Distance\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=None,\n",
    "    metric='precomputed',  # Use precomputed distance matrix\n",
    "    linkage='average',\n",
    "    distance_threshold=0.75\n",
    ")\n",
    "clustering.fit(cosine_dist_matrix)\n",
    "\n",
    "# Group Paragraphs Based on Clustering Results\n",
    "clusters = {}\n",
    "for idx, label in enumerate(clustering.labels_):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(paragraphs[idx])\n",
    "\n",
    "# Create Semantic Chunks from Clusters\n",
    "semantic_chunks = [\" \".join(cluster) for cluster in clusters.values()]\n",
    "\n",
    "# Inspect the First Few Semantic Chunks\n",
    "for i, chunk in enumerate(semantic_chunks[:3]):\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk[:500])  # Print the first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8921c0",
   "metadata": {},
   "source": [
    "Test - Extracting Middle Chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a235c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Middle Chunk 1:\n",
      "System.out.printf(\"CreateBucket Response: %s%n\", respCreateBucket.toString()); System.out.printf(\"CreateAccessPoint Response: %s%n\", respCreateAP.toString()); System.out.println(\"Endpoint is created and its ARN is \" + System.out.printf(\"CreateBucket Response: %s%n\", respCreateBucket.toString()); System.out.printf(\"PutBucketPolicy Response: %s%n\", System.out.printf(\"GetBucketPolicy Response: %s%n\", System.out.printf(\"ListRegionalBuckets Response: %s%n\", System.out.printf(\"GetBucket Response: %s%n\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Middle Chunk 2:\n",
      "command, replace the user input placeholders  with your own information. example, replace the user input placeholders  with your own information. placeholders  with your own information. placeholders  with your own information. replace the user input placeholders  with your own information. example, replace each user input placeholder  with your own information. policy1.json . Replace the user input placeholders  with your own information. command, replace the user input placeholders  with your \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Middle Chunk 3:\n",
      "public String createAccessPoint(String bucketArn, String accessPointName) { CreateAccessPointRequest reqCreateAP = new CreateAccessPointRequest() CreateAccessPointResult respCreateAP = return respCreateAP.getAccessPointArn(); public String createAccessPoint(String bucketArn, String accessPointName) { CreateAccessPointRequest reqCreateAP = new CreateAccessPointRequest() CreateAccessPointResult respCreateAP = return respCreateAP.getAccessPointArn(); GetAccessPointRequest reqGetAP = new GetAccessPo\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the total number of chunks\n",
    "total_chunks = len(semantic_chunks)\n",
    "\n",
    "# Define the middle range to inspect, for example, extract 3 chunks from the middle\n",
    "middle_start = total_chunks // 2 - 1  # Start from the middle, adjust -1 for indexing\n",
    "middle_end = min(middle_start + 3, total_chunks)  # Extract 3 chunks or up to the last chunk if less available\n",
    "\n",
    "# Extract and inspect the middle chunks\n",
    "for i, chunk in enumerate(semantic_chunks[middle_start:middle_end], start=1):\n",
    "    print(f\"Middle Chunk {i}:\")\n",
    "    print(chunk[:500])  # Print the first 500 characters of each chunk to avoid excessive output\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57711d",
   "metadata": {},
   "source": [
    "## Different Chunking method (not semantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1f823b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Advanced method - Split by chunk for S3 Outposts PDF\n",
    "\n",
    "# Step 1: Convert PDF to text\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Extract text from PDF using PyPDF2\n",
    "with open('./s3-outposts.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(reader.pages)):\n",
    "        page = reader.pages[page_num]\n",
    "        extracted_text = page.extract_text()\n",
    "        if extracted_text:\n",
    "            text += extracted_text\n",
    "\n",
    "# Step 2: Save to .txt and reopen (helps prevent issues)\n",
    "with open('s3-outposts.txt', 'w') as f:\n",
    "    f.write(text)\n",
    "\n",
    "with open('s3-outposts.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 3: Create function to count tokens\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Step 4: Split text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=24,\n",
    "    length_function=count_tokens,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.create_documents([text])\n",
    "\n",
    "# Step 5: Quick data visualization to ensure chunking was successful\n",
    "# Create a list of token counts\n",
    "token_counts = [count_tokens(chunk.page_content) for chunk in chunks]\n",
    "\n",
    "# Create a DataFrame from the token counts\n",
    "df = pd.DataFrame({'Token Count': token_counts})\n",
    "\n",
    "# Create a histogram of the token count distribution\n",
    "df.hist(bins=40)\n",
    "\n",
    "# Show the plot\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of Token Count Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5c8926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1:\n",
      "User Guide\n",
      "Amazon S3 on Outposts\n",
      "API Version 2006-03-01\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide\n",
      "Amazon S3 on Outposts: User Guide\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n",
      "Amazon's trademarks and trade dress may not be used in connection with any product or service \n",
      "that is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \n",
      "manner that dis\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 2:\n",
      "Getting started with S3 on Outposts...........................................................................................14\n",
      "Using the S3 console................................................................................................................................14\n",
      "Create a bucket, an access point, and an endpoint.......................................................................15\n",
      "Next steps.......................................................................................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Inspect a couple of chunks\n",
    "for i, chunk in enumerate(chunks[:2]):  # Display the first 2 chunks\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunk.page_content[:500])  # Print the first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16de3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 116:\n",
      "•An object key\n",
      "•An HTTP method (PUT for uploading objects)\n",
      "•An expiration date and time\n",
      "A presigned URL is valid only for the speciﬁed duration. That is, you must start the action that's \n",
      "allowed by the URL before the expiration date and time. You can use a presigned URL multiple \n",
      "times, up to the expiration date and time. If you created a presigned URL by using a temporary \n",
      "token, then the URL expires when the token expires, even if you created the URL with a later \n",
      "expiration time.\n",
      "If the acti\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk 117:\n",
      "outpostAccessPointArn, String keyName) { \n",
      "        try { \n",
      "            PutObjectRequest objectRequest = PutObjectRequest.builder() \n",
      "                    .bucket(accessPointArn) \n",
      "                    .key(keyName) \n",
      "                    .contentType(\"text/plain\") \n",
      "                    .build(); \n",
      "            PutObjectPresignRequest presignRequest = \n",
      " PutObjectPresignRequest.builder() \n",
      "                    .signatureDuration(Duration.ofMinutes(10)) \n",
      "                    .putObjectRequest(objectRequest) \n",
      "   \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Inspect middle chunks\n",
    "middle_index = len(chunks) // 2\n",
    "for i in range(middle_index - 1, middle_index + 1):  # Display two middle chunks\n",
    "    print(f\"Chunk {i+1}:\")\n",
    "    print(chunks[i].page_content[:500])  # Print the first 500 characters of each chunk\n",
    "    print(\"\\n\" + \"-\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae8630c",
   "metadata": {},
   "source": [
    "## Downloading the chunks in json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9b16fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked data saved as chunked_data.json\n"
     ]
    }
   ],
   "source": [
    "# will write/run later\n",
    "import json\n",
    "\n",
    "# Assuming `chunks` is the list of chunked data you already have.\n",
    "# Convert chunks to a list of dictionaries for JSON serialization\n",
    "chunk_data = [{\"chunk\": chunk.page_content} for chunk in chunks]\n",
    "\n",
    "# Save the chunks to a JSON file\n",
    "with open(\"chunked_data.json\", \"w\") as json_file:\n",
    "    json.dump(chunk_data, json_file, indent=4)\n",
    "\n",
    "print(\"Chunked data saved as chunked_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b38b192",
   "metadata": {},
   "source": [
    "## Embed text and store embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b562095",
   "metadata": {},
   "source": [
    "This code is designed to generate better-quality embeddings, making it suitable for tasks like semantic search, document clustering, or question answering systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69a4bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.4198e-02, -2.7816e-01, -5.1258e-02, -5.8414e-02, -1.1105e-02,\n",
      "          3.8111e-02,  2.9247e-01, -1.1949e-01, -2.9434e-02,  3.7466e-02,\n",
      "         -6.1046e-02,  4.1798e-02,  6.9489e-02,  1.7831e-01,  2.4960e-02,\n",
      "          1.5770e-01,  8.4875e-02, -1.6331e-02,  5.2857e-03,  3.6234e-03,\n",
      "          5.8174e-03,  1.9392e-03, -6.3071e-02, -2.0267e-01,  1.4423e-01,\n",
      "          6.4144e-02, -9.6636e-03, -1.6701e-03, -6.2568e-02, -1.1630e-01,\n",
      "          8.2119e-02, -1.5075e-01,  7.3914e-02, -7.3985e-02,  3.9752e-06,\n",
      "         -4.5764e-02, -1.1506e-01, -4.0145e-02, -2.3353e-01,  3.7105e-03,\n",
      "          5.3823e-02,  1.2140e-01, -2.3521e-02,  1.5621e-02, -7.6373e-02,\n",
      "         -1.2774e-01,  1.1575e-01, -8.2232e-02, -8.1675e-02,  4.2691e-03,\n",
      "         -2.5539e-02,  1.3639e-01, -2.7926e-01, -1.9670e-02,  1.2862e-01,\n",
      "          6.0984e-02, -8.6446e-02,  8.6982e-02,  1.8363e-02,  5.0157e-02,\n",
      "          8.9227e-02, -8.5671e-02, -1.5144e-02,  1.6215e-01,  2.2825e-01,\n",
      "          1.3746e-01, -1.5653e-01, -9.0133e-03, -9.6790e-02, -2.1436e-01,\n",
      "          2.1991e-01,  1.7092e-03, -6.8449e-02,  7.8137e-02, -1.9427e-03,\n",
      "          9.8571e-02, -6.7336e-03, -9.8636e-02,  1.2975e-01,  6.0886e-02,\n",
      "         -1.4382e-01,  7.1682e-02, -5.4599e-02,  1.2856e-01,  5.2069e-02,\n",
      "          2.5573e-01, -1.4255e-01,  3.4967e-02, -1.5182e-01,  1.5862e-01,\n",
      "         -1.7363e-02, -5.5670e-02,  1.7269e-01,  3.6795e-02, -3.4608e-02,\n",
      "         -9.5125e-02, -3.8455e-02, -2.6863e-02, -1.1026e-01,  2.6975e-01,\n",
      "          8.9664e-02, -1.5622e-02, -7.2840e-02,  1.0356e-02, -1.0166e-01,\n",
      "         -3.9470e-02, -4.1071e-03,  6.9881e-02,  1.9150e-02,  2.8414e-02,\n",
      "          1.6412e-01, -6.3526e-02, -9.3987e-02,  1.0730e-01, -1.8621e-02,\n",
      "         -1.3158e-01,  2.0399e-01,  4.1152e-02,  1.0004e-01,  6.2062e-02,\n",
      "          2.8096e-02,  1.1585e-01, -2.5618e-02, -1.2266e-01,  3.1063e-02,\n",
      "         -3.9952e-02, -3.1873e-02,  2.8767e-02,  1.1564e-01, -3.2838e-02,\n",
      "         -5.6808e-03, -1.1538e-01,  6.3546e-02,  2.7132e-02,  7.5974e-02,\n",
      "         -1.3360e-01,  1.1105e-01, -2.6331e-02,  7.4779e-02,  2.0773e-01,\n",
      "          1.7109e-01, -7.3609e-03, -1.1165e-01, -3.3348e-02,  3.0128e-02,\n",
      "          7.5201e-02, -1.0061e-01,  1.5128e-01,  2.7048e-02, -8.6960e-02,\n",
      "          1.4956e-01, -1.3603e-01, -2.4510e-01, -6.0761e-02, -5.6884e-02,\n",
      "         -3.2860e-02, -9.3095e-02, -2.1597e-01,  3.8299e-02, -3.5330e-02,\n",
      "          3.9322e-02,  1.5305e-02, -5.4149e-02,  2.8599e-02, -1.5731e-01,\n",
      "          4.3283e-02,  1.3072e-01,  1.1277e-01, -1.1853e-01,  1.6344e-02,\n",
      "         -2.9892e-02,  6.1163e-03,  1.2878e-01, -1.4373e-01,  1.0153e-02,\n",
      "          7.5790e-02, -6.2286e-02, -1.6137e-01, -1.3851e-01,  1.6333e-01,\n",
      "         -5.4331e-02, -1.9761e-01, -3.1234e-02,  1.9129e-01, -1.2345e-01,\n",
      "         -1.1873e-02, -1.3522e-01,  2.0085e-01,  5.5788e-02,  6.1303e-02,\n",
      "         -9.7698e-02, -1.5387e-03, -1.3540e-01,  4.5018e-02, -3.6722e-02,\n",
      "         -4.8638e-02,  4.5793e-02,  1.4215e-01, -1.3455e-01,  1.9756e-02,\n",
      "          1.0853e-01, -1.3486e-02,  1.0147e-01,  2.0304e-01,  8.6097e-02,\n",
      "          7.1027e-02, -1.6133e-01, -4.0272e-02, -3.3347e-02, -4.6906e-02,\n",
      "          7.5942e-02,  6.3859e-02,  6.8785e-03, -1.0666e-01, -1.2899e-01,\n",
      "          9.1631e-02,  3.1525e-02,  1.1525e-01,  5.5197e-02,  3.0902e-02,\n",
      "         -1.4673e-03, -1.7973e-01,  4.9123e-02, -4.7763e-02, -6.4068e-02,\n",
      "          1.4566e-01, -1.3372e-01,  9.5765e-02, -8.1594e-02, -1.6481e-01,\n",
      "         -3.5859e-02, -8.2845e-02,  6.1318e-03,  1.3907e-01, -5.3303e-05,\n",
      "          1.5663e-01,  1.3999e-01,  1.8410e-01, -6.5269e-02,  1.2971e-01,\n",
      "          2.4620e-01, -2.2991e-01,  2.2339e-03,  1.0291e-02, -3.9112e-02,\n",
      "         -1.7624e-01,  1.0073e-01,  2.5164e-02, -3.1877e-02, -5.6135e-02,\n",
      "          1.0254e-01, -1.3339e-02, -2.9418e-02,  1.3310e-02,  3.1728e-03,\n",
      "          3.2534e-02,  2.9845e-02,  1.9460e-01,  2.7126e-01,  9.3637e-02,\n",
      "         -1.3565e-01, -2.3012e-02, -7.7406e-02,  5.5105e-02, -5.0169e-02,\n",
      "         -1.9305e-01,  1.8068e-01,  8.0123e-02,  1.6776e-01, -9.1326e-03,\n",
      "          8.6825e-02,  6.6765e-02,  1.3194e-01, -1.8723e-02,  4.7362e-02,\n",
      "          4.2611e-02, -3.8035e-02,  1.9928e-02,  8.7545e-02,  3.7654e-02,\n",
      "          1.0451e-01,  3.4449e-03,  8.3669e-02, -3.5385e-02,  7.9506e-02,\n",
      "          1.6555e-02, -2.3241e-02, -1.8990e-03, -1.3450e-02,  3.1915e-02,\n",
      "         -7.4120e-02,  2.3960e-02,  7.4734e-02, -5.3468e-02, -4.6000e-02,\n",
      "         -2.2095e-01,  1.2676e-01,  1.4615e-01, -5.0900e-02, -1.4038e-01,\n",
      "         -1.0929e-01,  1.4180e-02,  5.4611e-02, -8.3454e-02,  1.1066e-01,\n",
      "         -5.4718e-02, -4.2462e-02,  8.6795e-02, -1.0168e-01, -2.9540e-01,\n",
      "         -1.0935e-02,  4.0119e-02, -1.9660e-03,  3.4698e-02,  3.6738e-02,\n",
      "          6.0188e-02, -1.4713e-01,  8.8927e-02, -7.7487e-02,  1.5188e-01,\n",
      "         -4.7196e-02, -7.4910e-02,  3.6364e-02, -7.3755e-02, -8.1338e-02,\n",
      "          5.0210e-02, -7.0725e-02, -7.5540e-02,  1.4882e-02, -1.0135e-01,\n",
      "         -2.2048e-02, -5.7398e-02,  3.2158e-02,  1.0488e-01, -1.4480e-01,\n",
      "         -9.8754e-02, -1.1665e-01, -3.5087e-01,  7.5262e-02, -5.8411e-02,\n",
      "          1.7375e-01, -2.9044e-02,  1.5299e-01,  1.3025e-01,  4.6732e-03,\n",
      "         -1.3446e-01, -2.8546e-01,  5.2554e-02,  4.4964e-02, -1.1881e-02,\n",
      "          2.8776e-01,  9.6022e-02, -9.8100e-02,  1.2263e-01,  5.9130e-02,\n",
      "         -2.1082e-02, -2.4223e-01,  6.9962e-02,  1.1257e-02, -8.6964e-02,\n",
      "         -1.8775e-01,  1.9518e-02,  8.6605e-02, -1.6309e-01, -8.3989e-02,\n",
      "          1.3327e-01,  1.1665e-01,  1.4947e-02, -5.3543e-02,  5.3131e-02,\n",
      "          6.3212e-02, -7.4898e-02,  1.5345e-02, -3.0023e-02, -9.6678e-02,\n",
      "         -5.3075e-02,  5.0645e-02, -9.1660e-02,  1.6027e-02,  1.2399e-01,\n",
      "         -3.0473e-02, -7.5204e-02,  1.7789e-02, -3.8922e-02, -1.8085e-01,\n",
      "         -7.9286e-03, -1.6381e-01, -9.6367e-03, -1.4162e-01,  2.3552e-03,\n",
      "          7.8641e-02,  8.4659e-02, -2.5308e-02,  1.5217e-01,  1.8717e-01,\n",
      "          1.2728e-02, -2.5999e-01,  3.3798e-02, -5.4675e-03,  1.1397e-01,\n",
      "          1.2210e-01, -1.0532e-01, -1.7722e-01, -1.1954e-01, -2.6227e-01,\n",
      "          5.1220e-02, -7.7078e-02, -1.3771e-01, -6.8409e-02,  1.1108e-02,\n",
      "         -1.2385e-01,  2.5879e-01,  1.6140e-01,  3.9862e-03, -1.4186e-01,\n",
      "          1.1232e-01,  1.4205e-02,  1.4995e-01,  2.4053e-02, -9.2956e-03,\n",
      "         -1.0371e-01, -6.2097e-02,  1.3380e-01, -2.7261e-01,  9.6607e-02,\n",
      "         -4.3172e-02, -3.0518e-02,  1.9162e-01,  5.2736e-03, -7.6440e-02,\n",
      "         -1.1866e-01,  9.8933e-02,  2.6161e-02, -8.4670e-02, -1.0253e-01,\n",
      "          2.1365e-01,  7.0964e-02, -5.5876e-03, -6.0989e-03,  1.5458e-02,\n",
      "         -3.4511e-02,  6.8838e-02, -1.4322e-02, -1.8160e-03, -5.7836e-02,\n",
      "         -1.1880e-01,  6.4616e-02,  1.3394e-02, -1.6741e-01,  4.4535e-02,\n",
      "          7.0775e-03,  2.9842e-01,  3.8132e-02,  1.9339e-02, -7.6797e-02,\n",
      "         -2.3054e-02, -2.8223e-01,  5.6367e-02,  5.2882e-02,  1.5025e-01,\n",
      "          8.6851e-02,  6.0541e-02, -2.1216e-02,  1.5272e-01,  1.0440e-01,\n",
      "          1.5995e-02,  1.1482e-01, -2.6187e-01, -5.0651e-02, -7.5805e-02,\n",
      "          7.9092e-02,  2.8955e-02, -2.7486e-02, -2.7127e-02,  1.6249e-02,\n",
      "         -2.7460e-02, -5.5305e-02,  9.7864e-02, -1.5834e-01,  2.2023e-03,\n",
      "         -3.4742e-03, -6.8102e-02, -1.1170e-02, -4.2713e-02,  8.4847e-02,\n",
      "          1.2875e-02,  9.2074e-02, -1.5363e-02,  9.4380e-02,  5.5683e-02,\n",
      "         -1.0536e-01, -6.9557e-02,  2.6790e-02,  2.9878e-01,  1.2640e-01,\n",
      "         -1.5305e-01,  2.2543e-01,  3.9811e-02, -7.8366e-02, -1.9582e-02,\n",
      "          3.0312e-02,  4.1763e-02, -6.7696e-02,  1.0627e-01, -5.4540e-02,\n",
      "         -2.6731e-02, -1.6103e-01,  1.5138e-02,  9.8493e-02, -3.6484e-03,\n",
      "         -1.0353e-01,  1.4038e-01,  8.9182e-02,  6.8819e-02,  1.1848e-01,\n",
      "          8.1383e-03, -7.2196e-02,  2.2160e-02, -1.9362e-02, -8.7033e-02,\n",
      "          2.7064e-02, -4.2474e-02, -6.6657e-02, -3.8775e-02, -1.0586e-01,\n",
      "         -2.1199e-01,  3.6528e-02,  2.7508e-03,  1.1179e-01, -1.2387e-01,\n",
      "         -4.2110e-02, -2.7416e-02, -4.6620e-02,  5.2074e-03, -1.2136e-02,\n",
      "          9.3431e-02, -8.7043e-02, -9.5692e-03,  7.8849e-02,  6.6476e-02,\n",
      "          8.7099e-02,  5.3652e-02, -1.1674e-01,  1.9068e-01,  7.5534e-02,\n",
      "         -1.2037e-01,  1.1115e-02,  9.8575e-02, -1.2921e-02, -1.3767e-02,\n",
      "          1.4484e-02,  8.6262e-02, -2.8686e-01,  7.0623e-02, -2.1919e-02,\n",
      "         -1.5050e-32,  1.5161e-01, -2.2934e-01,  1.2212e-01, -5.1941e-02,\n",
      "         -3.2539e-02,  1.6494e-01, -4.7719e-02, -1.0656e-01, -4.0392e-02,\n",
      "         -5.4825e-02,  3.6801e-03,  1.5790e-01,  9.2695e-02,  8.5748e-02,\n",
      "         -9.6485e-02,  7.2253e-02, -4.7024e-02,  4.4800e-02, -1.4166e-01,\n",
      "         -1.4663e-02,  8.6423e-02,  4.2134e-02,  8.0498e-02, -5.4115e-03,\n",
      "         -1.0432e-01, -1.0201e-01, -7.1643e-02, -3.9399e-03, -9.5211e-02,\n",
      "         -4.3646e-02,  4.9398e-02, -3.8639e-02, -5.1933e-02, -6.0792e-02,\n",
      "          5.4186e-03,  7.9348e-02,  6.4082e-02,  5.9387e-02, -8.7297e-04,\n",
      "         -4.2279e-02, -7.5871e-02,  1.2419e-02, -5.1704e-02,  3.8521e-03,\n",
      "         -1.1697e-01,  5.6018e-02, -1.7402e-02, -6.1858e-02, -1.0847e-01,\n",
      "         -7.9223e-02,  1.5583e-01, -7.7857e-02, -5.7275e-02,  2.0795e-01,\n",
      "         -5.8749e-02,  3.4954e-02, -1.2393e-01, -1.3657e-01,  6.3162e-02,\n",
      "         -4.2249e-02, -1.0653e-01,  1.3206e-01, -1.9843e-01, -8.0326e-02,\n",
      "         -1.3827e-01,  9.7739e-02, -2.5280e-01, -2.3065e-01,  3.4915e-02,\n",
      "          6.8419e-02,  7.6895e-02, -2.3673e-02,  6.5336e-02, -5.6506e-02,\n",
      "         -1.2899e-01, -1.4618e-01,  1.2586e-01,  4.5889e-02, -1.4363e-03,\n",
      "         -6.0013e-02,  1.9196e-01,  3.9981e-03,  1.3569e-01,  1.3719e-02,\n",
      "          1.3955e-02, -1.8164e-01, -3.7036e-02, -1.3668e-01,  6.8435e-02,\n",
      "          7.2817e-02, -1.4010e-01,  2.4591e-01,  1.1044e-01,  1.5234e-01,\n",
      "          1.4451e-01,  1.4410e-01, -4.4314e-02,  8.1845e-02, -5.3050e-02,\n",
      "         -6.8710e-02, -9.5286e-03,  4.3423e-02, -2.0424e-01,  7.4665e-02,\n",
      "          2.4134e-02, -4.0431e-02,  1.1528e-01,  1.1341e-01, -1.1039e-01,\n",
      "          9.4445e-02,  4.5205e-03,  8.7061e-02, -3.7191e-02, -1.0770e-01,\n",
      "          2.3401e-02, -1.2049e-02,  1.1417e-01,  1.9658e-01,  8.0281e-03,\n",
      "         -1.2016e-01,  6.3955e-02, -9.1191e-02, -4.1744e-02, -4.1206e-02,\n",
      "         -8.4298e-02,  2.2186e-01, -3.5646e-01,  1.3183e-02,  2.9287e-02,\n",
      "          4.0023e-02, -2.1382e-02,  8.7051e-02,  6.4580e-07,  2.6121e-02,\n",
      "          1.6871e-01,  1.4509e-01, -8.5990e-02,  4.3703e-02, -3.0182e-02,\n",
      "          1.5750e-01, -5.5647e-03,  4.4853e-02, -3.0907e-02, -1.1703e-01,\n",
      "          8.8182e-02,  2.4155e-02,  4.6892e-02,  3.8014e-02, -8.9612e-03,\n",
      "         -2.0971e-01,  2.7049e-02, -4.9504e-02,  1.1605e-01,  1.3270e-01,\n",
      "          4.1052e-02,  6.0189e-02, -1.3334e-03,  2.5124e-02, -1.8577e-02,\n",
      "         -3.2889e-02,  9.4705e-02,  7.8688e-02,  8.0488e-02, -5.0370e-02,\n",
      "          2.2996e-01, -1.1830e-01, -6.1380e-02, -4.8160e-02, -6.0489e-02,\n",
      "         -2.1185e-01, -2.7806e-02,  3.0725e-02,  8.6471e-02, -1.6264e-02,\n",
      "         -1.9693e-01, -1.8522e-01,  2.9538e-02,  1.9447e-02, -2.3520e-02,\n",
      "         -2.9751e-02,  5.1436e-02,  1.5206e-01, -1.1124e-01, -1.2670e-01,\n",
      "          3.7368e-02, -1.6174e-01, -6.7102e-02, -3.7862e-02, -1.6929e-01,\n",
      "         -2.0125e-01, -1.0404e-01,  5.3489e-02,  2.5661e-02,  8.4846e-03,\n",
      "          1.6891e-01,  3.1061e-02,  4.5157e-02, -1.3788e-01,  1.5428e-03,\n",
      "         -2.8132e-02,  4.5358e-34, -3.6461e-02,  1.0052e-01,  1.1983e-01,\n",
      "          5.2908e-02,  8.5664e-02,  1.0874e-04,  1.9206e-01, -8.5679e-02,\n",
      "         -2.6661e-02, -9.5251e-03, -1.3828e-01]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Union\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "import tiktoken  # Tokenizer library\n",
    "import PyPDF2\n",
    "\n",
    "# Configuration for the embedding model\n",
    "# I have updated the model to a more advanced version for better embeddings.\n",
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "DIMENSIONALITY = 768  # Updated dimensionality according to the new model\n",
    "THRESHOLD = 0.8  # Threshold for semantic similarity splitting\n",
    "MAX_TOKENS = 20000  # Max tokens per request\n",
    "MAX_INSTANCES = 250  # Max instances per request (sentences)\n",
    "\n",
    "# Load the Hugging Face model and tokenizer\n",
    "# The model here is an updated version of the previous one; it gives better embeddings.\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Example usage\n",
    "# The code below is just a placeholder to show how you might use the model and tokenizer later in your code.\n",
    "\n",
    "def get_embeddings(text: str):\n",
    "    \"\"\" Get embeddings for the given text using the model and tokenizer. \"\"\"\n",
    "    tokens = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**tokens)\n",
    "    # Depending on the model, we often use the mean of the last hidden state as the embedding\n",
    "    embeddings = model_output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "# Example text\n",
    "example_text = \"Amazon S3 on Outposts helps you extend S3 storage to your on-premises environments.\"\n",
    "embedding = get_embeddings(example_text)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451dbf47",
   "metadata": {},
   "source": [
    "## Generating metadata for text chunks using a LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c13df",
   "metadata": {},
   "source": [
    "Function 1: generate_metadata_for_chunks(llm, chunks, max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0948a3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to metadata_results_outposts.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# Load T5 model and tokenizer\n",
    "MODEL_NAME = \"t5-small\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load the chunks from a saved JSON file\n",
    "with open(\"chunked_data.json\", \"r\") as file:\n",
    "    chunk_data = json.load(file)\n",
    "\n",
    "# Extract the chunk text from the loaded JSON data\n",
    "chunks = [item['chunk'] for item in chunk_data]  # Correct key is 'chunk', not 'chunk_text'\n",
    "\n",
    "# Function to generate and save metadata\n",
    "def generate_and_save_metadata(model, tokenizer, chunks, output_file_path, max_tokens=2048):\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Define the prompt for metadata generation\n",
    "        prompt = f\"\"\"\n",
    "        The following text is a chunk from a larger document. Please generate the 2-3 most relevant topic headings and tags for this text:\n",
    "        Text: \"{truncated_chunk}\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize and prepare input for the model\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_tokens)\n",
    "\n",
    "        # Use the model to generate content based on the prompt\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_length=max_tokens)\n",
    "            response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response\n",
    "        })\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Metadata saved to {output_file_path}\")\n",
    "    return results\n",
    "\n",
    "# Use the function to generate metadata and save it\n",
    "metadata_results = generate_and_save_metadata(model, tokenizer, chunks, \"metadata_results_outposts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2f939",
   "metadata": {},
   "source": [
    "## Metadata gen on chunks - sample to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65a7cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Index: 0\n",
      "Chunk Text (truncated):\n",
      "User Guide\n",
      "Amazon S3 on Outposts\n",
      "API Version 2006-03-01\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide\n",
      "Amazon S3 on Outposts: User Guide\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n",
      "Amazon's trademarks and trade dress may not be used in connection with any product or service \n",
      "that is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \n",
      "manner that dis\n",
      "\n",
      "Generated Metadata:\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 1\n",
      "Chunk Text (truncated):\n",
      "Getting started with S3 on Outposts...........................................................................................14\n",
      "Using the S3 console................................................................................................................................14\n",
      "Create a bucket, an access point, and an endpoint.......................................................................15\n",
      "Next steps.......................................................................................\n",
      "\n",
      "Generated Metadata:\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 2\n",
      "Chunk Text (truncated):\n",
      "Working with S3 on Outposts objects.........................................................................................66\n",
      "Upload an object........................................................................................................................................67\n",
      "Copying an object......................................................................................................................................69\n",
      "Using the AWS SDK for Java......................................\n",
      "\n",
      "Generated Metadata:\n",
      "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the metadata results from the JSON file\n",
    "with open(\"metadata_results_outposts.json\", \"r\") as file:\n",
    "    metadata_results = json.load(file)\n",
    "\n",
    "# Function to print a couple of results to check\n",
    "def print_metadata_results(metadata_results, num_results=3):\n",
    "    for i, result in enumerate(metadata_results[:num_results]):\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:500])  # Display only the first 500 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "        print(result['metadata'])\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Print a few metadata results to verify\n",
    "print_metadata_results(metadata_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c57f041",
   "metadata": {},
   "source": [
    "## -- Updated Code for Metadata gen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "474b2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddb5428b4994204a39081e37a5edd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc535c8b84a34286a8d6642bad942468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffdef68f1084342a7add5b5de22a2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d8ec6549404fb7841f70a6a894c668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e9566945bc4aef8505391e50641f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dccfc18276e4cb2968e7598739fab4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6277130f662447fa545973cd9726602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/233 chunks...\n",
      "Processed 20/233 chunks...\n",
      "Processed 30/233 chunks...\n",
      "Processed 40/233 chunks...\n",
      "Processed 50/233 chunks...\n",
      "Processed 60/233 chunks...\n",
      "Processed 70/233 chunks...\n",
      "Processed 80/233 chunks...\n",
      "Processed 90/233 chunks...\n",
      "Processed 100/233 chunks...\n",
      "Processed 110/233 chunks...\n",
      "Processed 120/233 chunks...\n",
      "Processed 130/233 chunks...\n",
      "Processed 140/233 chunks...\n",
      "Processed 150/233 chunks...\n",
      "Processed 160/233 chunks...\n",
      "Processed 170/233 chunks...\n",
      "Processed 180/233 chunks...\n",
      "Processed 190/233 chunks...\n",
      "Processed 200/233 chunks...\n",
      "Processed 210/233 chunks...\n",
      "Processed 220/233 chunks...\n",
      "Processed 230/233 chunks...\n",
      "Metadata saved to metadata_results_outposts_improved.json\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metadata_gen_outposts_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Print a few metadata results to verify the improvement\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m print_metadata_results(metadata_gen_outposts_new)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata_gen_outposts_new' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# Load a larger and more powerful model\n",
    "MODEL_NAME = \"google/flan-t5-large\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Function to generate and save metadata for each chunk\n",
    "def generate_and_save_metadata(model, tokenizer, chunks, output_file_path, max_tokens=1024):\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Truncate the chunk if it exceeds the max_tokens limit\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Refine the prompt for better results\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant. Your task is to generate concise, meaningful topic headings and tags.\n",
    "        Below is a chunk of text from a larger document. Please generate the 2-3 most relevant topic headings and tags that accurately describe the content of this text.\n",
    "        \n",
    "        Text: \"{truncated_chunk}\"\n",
    "\n",
    "        Please return your response in the format:\n",
    "        - Headings: [heading1, heading2, ...]\n",
    "        - Tags: [tag1, tag2, ...]\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize and prepare input for the model\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_tokens)\n",
    "\n",
    "        # Use the model to generate content based on the prompt\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_length=max_tokens)\n",
    "            response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response\n",
    "        })\n",
    "\n",
    "        # Print progress for every 10 chunks\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(chunks)} chunks...\")\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Metadata saved to {output_file_path}\")\n",
    "    return results\n",
    "\n",
    "# Assuming `chunks` is the list of chunked data you already have.\n",
    "# Use the function to generate metadata and save it\n",
    "metadata_results = generate_and_save_metadata(model, tokenizer, chunks, \"metadata_results_outposts_improved.json\")\n",
    "\n",
    "# Function to print a couple of results to check the generated metadata\n",
    "def print_metadata_results(metadata_results, num_results=3):\n",
    "    for i, result in enumerate(metadata_results[:num_results]):\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:500])  # Display only the first 500 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "        print(result['metadata'])\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c45bce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk Index: 0\n",
      "Chunk Text (truncated):\n",
      "User Guide\n",
      "Amazon S3 on Outposts\n",
      "API Version 2006-03-01\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide\n",
      "Amazon S3 on Outposts: User Guide\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n",
      "Amazon's trademarks and trade dress may not be used in connection with any product or service \n",
      "that is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \n",
      "manner that dis\n",
      "\n",
      "Generated Metadata:\n",
      "Amazon S3 on Outposts User Guide\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 1\n",
      "Chunk Text (truncated):\n",
      "Getting started with S3 on Outposts...........................................................................................14\n",
      "Using the S3 console................................................................................................................................14\n",
      "Create a bucket, an access point, and an endpoint.......................................................................15\n",
      "Next steps.......................................................................................\n",
      "\n",
      "Generated Metadata:\n",
      "Amazon S3 on Outposts\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 2\n",
      "Chunk Text (truncated):\n",
      "Working with S3 on Outposts objects.........................................................................................66\n",
      "Upload an object........................................................................................................................................67\n",
      "Copying an object......................................................................................................................................69\n",
      "Using the AWS SDK for Java......................................\n",
      "\n",
      "Generated Metadata:\n",
      "Outposts Objects\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print a few metadata results to verify the improvement\n",
    "print_metadata_results(metadata_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44dd18",
   "metadata": {},
   "source": [
    "## still improvising code for Metadata Gen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86deadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/233 chunks...\n",
      "Processed 20/233 chunks...\n",
      "Processed 30/233 chunks...\n",
      "Processed 40/233 chunks...\n",
      "Processed 50/233 chunks...\n",
      "Processed 60/233 chunks...\n",
      "Processed 70/233 chunks...\n",
      "Processed 80/233 chunks...\n",
      "Processed 90/233 chunks...\n",
      "Processed 100/233 chunks...\n",
      "Processed 110/233 chunks...\n",
      "Processed 120/233 chunks...\n",
      "Processed 130/233 chunks...\n",
      "Processed 140/233 chunks...\n",
      "Processed 150/233 chunks...\n",
      "Processed 160/233 chunks...\n",
      "Processed 170/233 chunks...\n",
      "Processed 180/233 chunks...\n",
      "Processed 190/233 chunks...\n",
      "Processed 200/233 chunks...\n",
      "Processed 210/233 chunks...\n",
      "Processed 220/233 chunks...\n",
      "Processed 230/233 chunks...\n",
      "Metadata saved to metadata_results_outposts_refined_v2.json\n",
      "Chunk Index: 0\n",
      "Chunk Text (truncated):\n",
      "User Guide\n",
      "Amazon S3 on Outposts\n",
      "API Version 2006-03-01\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.Amazon S3 on Outposts User Guide\n",
      "Amazon S3 on Outposts: User Guide\n",
      "Copyright © 2024 Amazon Web Services, Inc. and/or its aﬃliates. All rights reserved.\n",
      "Amazon's trademarks and trade dress may not be used in connection with any product or service \n",
      "that is not Amazon's, in any manner that is likely to cause confusion among customers, or in any \n",
      "manner that dis\n",
      "\n",
      "Generated Metadata:\n",
      "[Amazon S3 on Outposts User Guide]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 1\n",
      "Chunk Text (truncated):\n",
      "Getting started with S3 on Outposts...........................................................................................14\n",
      "Using the S3 console................................................................................................................................14\n",
      "Create a bucket, an access point, and an endpoint.......................................................................15\n",
      "Next steps.......................................................................................\n",
      "\n",
      "Generated Metadata:\n",
      "[Amazon S3 on Outposts, Getting Started]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Chunk Index: 2\n",
      "Chunk Text (truncated):\n",
      "Working with S3 on Outposts objects.........................................................................................66\n",
      "Upload an object........................................................................................................................................67\n",
      "Copying an object......................................................................................................................................69\n",
      "Using the AWS SDK for Java......................................\n",
      "\n",
      "Generated Metadata:\n",
      "[S3 on Outposts, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects, S3 on Outposts objects\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "MODEL_NAME = \"google/flan-t5-large\"  # Consider using a stronger model if available\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Function to generate and save metadata for each chunk\n",
    "def generate_and_save_metadata(model, tokenizer, chunks, output_file_path, max_tokens=1024):\n",
    "    results = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        truncated_chunk = chunk[:max_tokens]\n",
    "\n",
    "        # Refined prompt with an explicit example and instructions\n",
    "        prompt = f\"\"\"\n",
    "        You are an AI assistant. Your task is to generate concise, meaningful topic headings and tags.\n",
    "        Below is a chunk of text from a larger document. Please generate the 2-3 most relevant topic headings and tags that accurately describe the content of this text.\n",
    "        \n",
    "        Example Output:\n",
    "        - Headings: [Amazon S3 Bucket Policies, Creating S3 Endpoints]\n",
    "        - Tags: [S3 Outposts, Bucket Policies, Endpoints]\n",
    "\n",
    "        Text: \"{truncated_chunk}\"\n",
    "\n",
    "        Please return your response in the format:\n",
    "        - Headings: [heading1, heading2, ...]\n",
    "        - Tags: [tag1, tag2, ...]\n",
    "        \"\"\"\n",
    "\n",
    "        # Tokenize and prepare input for the model\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_tokens)\n",
    "\n",
    "        # Use the model to generate content based on the prompt\n",
    "        with torch.no_grad():\n",
    "            output = model.generate(**inputs, max_length=max_tokens)\n",
    "            response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "        # Store the response metadata (topic headings and tags)\n",
    "        results.append({\n",
    "            \"chunk_index\": i,\n",
    "            \"chunk_text\": truncated_chunk,\n",
    "            \"metadata\": response\n",
    "        })\n",
    "\n",
    "        # Print progress for every 10 chunks\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(chunks)} chunks...\")\n",
    "\n",
    "    # Save the results to a JSON file\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "\n",
    "    print(f\"Metadata saved to {output_file_path}\")\n",
    "    return results\n",
    "\n",
    "# Use the function to generate metadata and save it\n",
    "metadata_results = generate_and_save_metadata(model, tokenizer, chunks, \"metadata_results_outposts_refined_v2.json\")\n",
    "\n",
    "# Function to print a couple of results to check the generated metadata\n",
    "def print_metadata_results(metadata_results, num_results=3):\n",
    "    for i, result in enumerate(metadata_results[:num_results]):\n",
    "        print(f\"Chunk Index: {result['chunk_index']}\")\n",
    "        print(\"Chunk Text (truncated):\")\n",
    "        print(result['chunk_text'][:500])  # Display only the first 500 characters of the chunk text\n",
    "        print(\"\\nGenerated Metadata:\")\n",
    "        print(result['metadata'])\n",
    "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Print a few metadata results to verify the improvement\n",
    "print_metadata_results(metadata_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "465992ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Okay Metadata Gen has some issues, so lets take different approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d404d38",
   "metadata": {},
   "source": [
    "# Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba695ecc",
   "metadata": {},
   "source": [
    "Approach 1: Group Chunks with Common Tags (Clustering Similar Content)\n",
    "Instead of relying solely on metadata generation, we can try clustering or grouping chunks that share common themes or concepts. This can create more meaningful categories and help in organizing the content. Here’s a potential approach:\n",
    "\n",
    "Embed the Chunks: Use a pre-trained embedding model (e.g., sentence-transformers) to create vector embeddings for each chunk.\n",
    "Cluster the Embeddings: Apply a clustering algorithm, such as K-means or Agglomerative Clustering, to group similar chunks together.\n",
    "Assign Tags: For each cluster, we can either manually assign a tag or leverage the LLM to generate a summary for that cluster, which will be more informative because the cluster contains multiple related chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae59f0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 6 contains 16 chunks.\n",
      "Cluster 10 contains 4 chunks.\n",
      "Cluster 13 contains 18 chunks.\n",
      "Cluster 21 contains 7 chunks.\n",
      "Cluster 16 contains 17 chunks.\n",
      "Cluster 5 contains 13 chunks.\n",
      "Cluster 3 contains 21 chunks.\n",
      "Cluster 7 contains 5 chunks.\n",
      "Cluster 9 contains 12 chunks.\n",
      "Cluster 11 contains 10 chunks.\n",
      "Cluster 17 contains 10 chunks.\n",
      "Cluster 4 contains 18 chunks.\n",
      "Cluster 19 contains 2 chunks.\n",
      "Cluster 0 contains 12 chunks.\n",
      "Cluster 15 contains 5 chunks.\n",
      "Cluster 8 contains 6 chunks.\n",
      "Cluster 20 contains 9 chunks.\n",
      "Cluster 2 contains 8 chunks.\n",
      "Cluster 14 contains 8 chunks.\n",
      "Cluster 18 contains 15 chunks.\n",
      "Cluster 12 contains 9 chunks.\n",
      "Cluster 1 contains 8 chunks.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Step 1: Generate embeddings for each chunk using SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "chunk_embeddings = model.encode(chunks)\n",
    "\n",
    "# Step 2: Use Agglomerative Clustering to group similar chunks\n",
    "# Updated: Replace 'affinity' with 'metric' as per the newer scikit-learn version\n",
    "clustering_model = AgglomerativeClustering(\n",
    "    n_clusters=None, \n",
    "    distance_threshold=1.5, \n",
    "    metric='euclidean',  # Updated from 'affinity' to 'metric'\n",
    "    linkage='ward'\n",
    ")\n",
    "labels = clustering_model.fit_predict(chunk_embeddings)\n",
    "\n",
    "# Step 3: Organize chunks into clusters based on labels\n",
    "clusters = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in clusters:\n",
    "        clusters[label] = []\n",
    "    clusters[label].append(chunks[idx])\n",
    "\n",
    "# Step 4: Print the clusters to verify\n",
    "for cluster_id, cluster_chunks in clusters.items():\n",
    "    print(f\"Cluster {cluster_id} contains {len(cluster_chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53033e",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0952a1e",
   "metadata": {},
   "source": [
    "Approach 2: Hierarchical Indexing\n",
    "Hierarchical Indexing involves creating a structured way to navigate through the document's content. Instead of focusing on generating accurate tags, we create a table of contents and hierarchical layers that help navigate through different levels of information. Here's how we could do it:\n",
    "\n",
    "High-Level Summarization: Use an LLM to generate a general summary of the entire document first. This becomes the top-level hierarchy (e.g., main sections).\n",
    "Divide and Summarize: After that, we dive deeper into each section (e.g., clusters or groups of related chunks) and generate a sub-summary. This creates a tree-like structure.\n",
    "Create Indexing: Each chunk or summary is indexed hierarchically — for example:\n",
    "Chapter 1: Introduction\n",
    "Section 1.1: S3 on Outposts Overview\n",
    "Section 1.2: Bucket Creation and Management\n",
    "Chapter 2: Advanced Features\n",
    "Section 2.1: Access Points and Policies\n",
    "etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12f44b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Summary: user guide for Amazon S3 on Outposts. includes how to create buckets, manage access points, interact with API.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load T5 model and tokenizer\n",
    "MODEL_NAME = \"t5-small\"  # You can also try \"t5-base\" or \"t5-large\" for better results\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Your document summary prompt\n",
    "document_summary_prompt = \"summarize: User Guide for Amazon S3 on Outposts. This document explains the concepts, features, and setup instructions for using Amazon S3 on AWS Outposts, including how to create buckets, manage access points, and interact with the API.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(document_summary_prompt, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "# Generate summary using the model\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**inputs, max_length=100)\n",
    "\n",
    "# Decode the output to get the summary\n",
    "document_summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the summary\n",
    "print(\"Document Summary:\", document_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ec4bb",
   "metadata": {},
   "source": [
    "## Approach 3: Keyword Extraction and Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b5758",
   "metadata": {},
   "source": [
    "Approach 3: Keyword Extraction and Tagging\n",
    "Instead of relying on LLMs entirely for generating metadata, you can also try keyword extraction to create more meaningful tags:\n",
    "\n",
    "Use NLP Libraries: Libraries like RAKE, spaCy, or KeyBERT can extract keywords from each chunk.\n",
    "Group Related Keywords: Post-process these keywords to group similar concepts and create clusters of tags.\n",
    "Assign Tags to Chunks: Use these keyword groups to tag chunks more effectively.\n",
    "This approach can be especially effective when the LLM struggles to understand technical terms or repetitive content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05f640a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from keybert) (1.24.3)\n",
      "Requirement already satisfied: rich>=10.4.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from keybert) (1.5.2)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from keybert) (3.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from rich>=10.4.0->keybert) (2.15.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=0.22.2->keybert)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.46.2)\n",
      "Requirement already satisfied: tqdm in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sentence-transformers>=0.3.8->keybert) (9.4.0)\n",
      "Requirement already satisfied: filelock in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: requests in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.0)\n",
      "Requirement already satisfied: sympy in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2022.7.9)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/ramyashreekeshavamurthy/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
      "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, keybert\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.1\n",
      "    Uninstalling joblib-1.1.1:\n",
      "      Successfully uninstalled joblib-1.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed joblib-1.4.2 keybert-0.8.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4cb5db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0 Keywords: ['amazon s3', 's3 outposts', 'outposts s3', 'amazon trademarks', 'accessing s3']\n",
      "Chunk 1 Keywords: ['accessing s3', 'managing s3', 's3 outposts', 'using s3', 'networking s3']\n",
      "Chunk 2 Keywords: ['object s3', 'accessing s3', 'working s3', 'uploads s3', 's3 outposts']\n",
      "Chunk 3 Keywords: ['policy keys', 'sigv4 policy', 'creating vpc', 'vpc endpoint', 'endpoint policies']\n",
      "Chunk 4 Keywords: ['s3 apis', 's3 api', 'api s3', 'developing s3', 'conﬁguring s3']\n",
      "Chunk 5 Keywords: ['s3 access', 'accessing s3', 'access s3', 'manage s3', 's3 outposts']\n",
      "Chunk 6 Keywords: ['bucket access', 'buckets account', 's3 bucket', 'specify bucket', 'create bucket']\n",
      "Chunk 7 Keywords: ['aws management', 'api aws', 'aws s3', 'aws sdks', 'aws command']\n",
      "Chunk 8 Keywords: ['stored s3', 's3 storage', 'encryption s3', 'versioning s3', 's3 versioning']\n",
      "Chunk 9 Keywords: ['bucket access', 'access buckets', 'permissions s3', 'access s3', 'accessing s3']\n",
      "Chunk 10 Keywords: ['aws resources', 'aws resource', 'monitoring s3', 'aws service', 'aws organizations']\n",
      "Chunk 11 Keywords: ['aws services', 'aws management', 's3 aws', 'aws cloud', 'managing s3']\n",
      "Chunk 12 Keywords: ['s3 apis', 's3 aws', 'aws s3', 'aws command', 's3outposts aws']\n",
      "Chunk 13 Keywords: ['s3 outposts', 'outposts s3', 'outpost s3', 'aws outposts', 'managing s3']\n",
      "Chunk 14 Keywords: ['aws outposts', 's3 outposts', 'aws infrastructure', 'outposts s3', 's3 apis']\n",
      "Chunk 15 Keywords: ['encryption aws', 'conﬁgure s3', 'amazon s3', 'supported s3', 's3 inventory']\n",
      "Chunk 16 Keywords: ['aws outposts', 's3 outposts', 'outposts aws', 's3 apis', 'using aws']\n",
      "Chunk 17 Keywords: ['s3 apis', 'aws management', 'aws sdks', 'aws outposts', 's3 outposts']\n",
      "Chunk 18 Keywords: ['bucket versioning', 'versioning s3', 's3 versioning', 'managing s3', 's3 outposts']\n",
      "Chunk 19 Keywords: ['infrastructure aws', 'vpc amazon', 'cloud vpc', 'aws 10', 'networking s3']\n",
      "Chunk 20 Keywords: ['aws management', 'aws outposts', 's3 apis', 'api aws', 'using aws']\n",
      "Chunk 21 Keywords: ['s3controlclient createbucket', 'create s3', 'aws s3control', 'bucket api', 'create bucket']\n",
      "Chunk 22 Keywords: ['s3 access', 'aws s3control', 'aws s3', 's3 outposts', 'addressing aws']\n",
      "Chunk 23 Keywords: ['s3 outposts', 's3controlclient createaccesspoint', 'conﬁgure s3', 'aws s3outposts', 'using aws']\n",
      "Chunk 24 Keywords: ['ipv4pool coip', 'ipv4pool', 'pool ipv4pool', 'ipv4 pool', 'createendpoint amazons3outposts']\n",
      "Chunk 25 Keywords: ['networking s3', 's3outpostsclient createendpoint', 'accessing s3', 's3 outposts', 'createendpointresult s3outpostsclient']\n",
      "Chunk 26 Keywords: ['connectivity aws', 'accessing s3', 's3 outposts', 'aws outposts', 'outpost aws']\n",
      "Chunk 27 Keywords: ['s3 apis', 'aws s3', 's3 access', 'networking s3', 's3 outposts']\n",
      "Chunk 28 Keywords: ['cloud vpc', 'aws s3', 's3 endpoint', 's3 api', 'endpoint s3']\n",
      "Chunk 29 Keywords: ['s3 api', 'api s3', 's3 outposts', 'routed s3', 'managing s3']\n",
      "Chunk 30 Keywords: ['s3 apis', 'aws outposts', 'aws management', 'aws sdks', 'managing s3']\n",
      "Chunk 31 Keywords: ['bucket versioning', 'bucket naming', 'outposts bucket', 'naming buckets', 'create bucket']\n",
      "Chunk 32 Keywords: ['infrastructure aws', 'using aws', 'networking s3', 'bucket s3', 'aws resources']\n",
      "Chunk 33 Keywords: ['s3controlclient createbucket', 'bucketname createbucketrequest', 'createbucketrequest withbucket', 'createbucketrequest', 'respcreatebucket s3controlclient']\n",
      "Chunk 34 Keywords: ['tagging aws', 'bucket tagging', 's3control bucket', 'aws s3', 'guide aws']\n",
      "Chunk 35 Keywords: ['bucket policies', 'bucket policy', 'bucket permissions', 'policy bucket', 'permissions bucket']\n",
      "Chunk 36 Keywords: ['s3control bucket', 'bucket policy', 'adding bucket', 'bucket submit', 'bucket import']\n",
      "Chunk 37 Keywords: ['bucketarn putbucketpolicyrequest', 's3controlclient putbucketpolicy', 'bucket permission', 'bucket policies', 'bucket permissions']\n",
      "Chunk 38 Keywords: ['s3controlclient getbucketpolicy', 's3control bucket', 'aws s3control', 'bucketarn getbucketpolicyrequest', 'aws command']\n",
      "Chunk 39 Keywords: ['deleting bucket', 'delete bucket', 'deletes bucket', 'bucket permission', 's3control delete']\n",
      "Chunk 40 Keywords: ['bucket permissions', 'bucket policies', 'permissions bucket', 'bucket policy', 'policy bucket']\n",
      "Chunk 41 Keywords: ['condition aws', 'aws sourceip', 'bucket policy', 'aws s3', 'access bucket']\n",
      "Chunk 42 Keywords: ['notipaddress aws', 'policies ipv6', 'aws sourceip', 'ranges ipv6', 'access bucket']\n",
      "Chunk 43 Keywords: ['bucket condition', 'bucket doc', 's3outposts resource', 'bucket', 'example bucket']\n",
      "Chunk 44 Keywords: ['s3 apis', 'buckets aws', 'buckets s3', 'aws outposts', 's3 buckets']\n",
      "Chunk 45 Keywords: ['s3controlclient listregionalbuckets', 'buckets api', 'list buckets', 'list s3', 'listing buckets']\n",
      "Chunk 46 Keywords: ['s3 apis', 'aws s3', 's3 outposts', 'aws outposts', 'aws sdks']\n",
      "Chunk 47 Keywords: ['bucketarn getbucketrequest', 'bucket api', 's3controlclient getbucket', 'getbucket amazon', 'buckets aws']\n",
      "Chunk 48 Keywords: ['deleting bucket', 'delete bucket', 'buckets deleting', 'bucket delete', 'buckets deleted']\n",
      "Chunk 49 Keywords: ['s3 access', 'access points', 'points access', 'point access', 'points s3']\n",
      "Chunk 50 Keywords: ['aws s3control', 'aws sdk', 'following aws', 'using aws', 'aws cli']\n",
      "Chunk 51 Keywords: ['s3 api', 'alias s3', 'aws s3', 'bucket s3', 'point s3']\n",
      "Chunk 52 Keywords: ['point alias', 'alias amazon', 'aws s3', 's3 outposts', 'aws s3control']\n",
      "Chunk 53 Keywords: ['aws cli', 'aws s3control', 'information aws', 'following aws', 's3control access']\n",
      "Chunk 54 Keywords: ['bucket accesspointarn', 'bucket accesspointlist', 'aws s3control', 's3 outposts', 'aws s3']\n",
      "Chunk 55 Keywords: ['aws s3api', 'alias s3', 'aws command', 's3 key', 'buckets aliases']\n",
      "Chunk 56 Keywords: ['s3 access', 's3control access', 'aws s3control', 'following aws', 'information aws']\n",
      "Chunk 57 Keywords: ['s3 access', 's3 outposts', 'list s3', 'aws s3', 'aws s3control']\n",
      "Chunk 58 Keywords: ['s3control delete', 'point deleting', 'deleting access', 'delete access', 'deletes outposts']\n",
      "Chunk 59 Keywords: ['principal aws', 'information aws', 'policy api', 'aws s3control', 'aws cli']\n",
      "Chunk 60 Keywords: ['s3controlclient putaccesspointpolicy', 'services s3control', 'policy s3', 'aws command', 'respputaccesspointpolicy s3controlclient']\n",
      "Chunk 61 Keywords: ['s3control access', 'aws s3control', 'aws s3', 'following aws', 'information aws']\n",
      "Chunk 62 Keywords: ['endpoints s3', 's3 outposts', 'endpoint create', 'outposts endpoint', 'endpoints create']\n",
      "Chunk 63 Keywords: ['infrastructure aws', 'endpoint s3', 's3 outposts', 'using aws', 'aws management']\n",
      "Chunk 64 Keywords: ['aws s3outposts', 'infrastructure aws', 'following aws', 'using aws', 'aws cli']\n",
      "Chunk 65 Keywords: ['ipv4pool coip', 'withcustomerownedipv4pool ipv4pool', 'customerownedip withcustomerownedipv4pool', 'withcustomerownedipv4pool access', 'createendpoint amazons3outposts']\n",
      "Chunk 66 Keywords: ['endpoints aws', 's3 outposts', 'quotas s3', 'aws s3outposts', 'endpoint quotas']\n",
      "Chunk 67 Keywords: ['s3outpostsclient listendpoints', 's3 outposts', 'aws s3outposts', 'services s3outposts', 'conﬁgure s3']\n",
      "Chunk 68 Keywords: ['s3outpostsclient deleteendpoint', 'deleteendpoint deleteendpointrequest', 'deleteendpointrequest', 'deleteendpointrequest deleteendpointrequest', 'new deleteendpointrequest']\n",
      "Chunk 69 Keywords: ['aws s3', 'aws outposts', 'aws sdks', 'aws management', 's3 outposts']\n",
      "Chunk 70 Keywords: ['api aws', 'aws s3', 's3 outposts', 'aws sdk', 'aws sdks']\n",
      "Chunk 71 Keywords: ['object aws', 'aws management', 'aws s3api', 'api aws', 'aws s3']\n",
      "Chunk 72 Keywords: ['s3client putobject', 'upload object', 's3client amazons3clientbuilder', 'object upload', 'upload file']\n",
      "Chunk 73 Keywords: ['s3client putobject', 'amazonserviceexception transmitted', 'metadata s3client', 'amazonserviceexception', 'catch amazonserviceexception']\n",
      "Chunk 74 Keywords: ['aws management', 's3 amazons3clientbuilder', 'api aws', 'using aws', 'docs aws']\n",
      "Chunk 75 Keywords: ['s3client copyobject', 's3client amazons3clientbuilder', 'amazons3 s3client', 'destinationkey s3client', 'amazonserviceexception transmitted']\n",
      "Chunk 76 Keywords: ['object aws', 'aws s3api', 'aws s3', 's3 outposts', 'aws region']\n",
      "Chunk 77 Keywords: ['key s3object', 'amazonserviceexception', 'amazonaws amazonserviceexception', 'getobject amazon', 'model s3object']\n",
      "Chunk 78 Keywords: ['s3client getobject', 'fullobject s3client', 'bytes getobjectrequest', 'objectportion s3client', 'downloading object']\n",
      "Chunk 79 Keywords: ['s3client getobject', 'catch amazonserviceexception', 'amazonserviceexception transmitted', 'headeroverrideobject s3client', 'amazonserviceexception']\n",
      "Chunk 80 Keywords: ['aws s3', 'bucket access', 'bucket object', 'void displaytextinputstream', 'displaytextinputstream']\n",
      "Chunk 81 Keywords: ['api aws', 'outposts aws', 'aws s3api', 'outposts listobjectsv2', 's3 outposts']\n",
      "Chunk 82 Keywords: ['s3client amazons3clientbuilder', 's3 amazons3clientbuilder', 'amazons3 s3client', 'amazonaws amazonserviceexception', 'amazonserviceexception']\n",
      "Chunk 83 Keywords: ['s3objectsummary objectsummary', 's3client listobjectsv2', 's3objectsummary', 'req s3objectsummary', 'getkey objectsummary']\n",
      "Chunk 84 Keywords: ['aws s3', 's3 printstacktrace', 's3 outposts', 'api aws', 'objects s3']\n",
      "Chunk 85 Keywords: ['bucket deleteobject', 's3api delete', 'bucket delete', 'outposts deleteobject', 'deleting objects']\n",
      "Chunk 86 Keywords: ['deleteobjectrequest accesspointarn', 's3client deleteobject', 'deleteobject amazon', 'deleteobjectrequest', 'deleteobjectrequest public']\n",
      "Chunk 87 Keywords: ['deleteobjects amazon', 'amazonserviceexception', 'printstacktrace deleteobjects', 's3 amazons3clientbuilder', 'amazonaws amazonserviceexception']\n",
      "Chunk 88 Keywords: ['s3client deleteobjects', 'objects deleteobjectsrequest', 'successfully deleteobjectsresult', 'deleteobjectsrequest', 'new deleteobjectsrequest']\n",
      "Chunk 89 Keywords: ['s3client deleteobjects', 'delobjres getdeletedobjects', 'deleteobjects multiobjectdeleterequest', 'catch amazonserviceexception', 'amazonserviceexception']\n",
      "Chunk 90 Keywords: ['aws s3api', 'aws management', 'aws s3', 'api aws', 'using aws']\n",
      "Chunk 91 Keywords: ['s3client headbucket', 's3client amazons3clientbuilder', 's3 amazons3clientbuilder', 'headbucketrequest accesspointarn', 'amazons3 s3client']\n",
      "Chunk 92 Keywords: ['multipart uploads', 'multipart upload', 'uploads s3', 's3 amazons3clientbuilder', 'create s3']\n",
      "Chunk 93 Keywords: ['s3client initiatemultipartupload', 's3client amazons3clientbuilder', 'amazons3clientbuilder', 'amazons3 s3client', 's3client getobjectmetadata']\n",
      "Chunk 94 Keywords: ['copy copypartrequest', 'copypartrequest copyrequest', 'copypartresult byteposition', 'copypartrequest', 'arraylist copypartresult']\n",
      "Chunk 95 Keywords: ['s3client completemultipartupload', 's3client copypart', 'copyresponses s3client', 'completemultipartupload completerequest', 'completemultipartuploadrequest']\n",
      "Chunk 96 Keywords: ['s3 amazons3clientbuilder', 's3 printstacktrace', 'amazonserviceexception', 'amazonaws amazonserviceexception', 's3 amazons3']\n",
      "Chunk 97 Keywords: ['s3client initiatemultipartupload', 's3client amazons3clientbuilder', 'multipart upload', 'amazons3clientbuilder', 'amazons3 s3client']\n",
      "Chunk 98 Keywords: ['copypartresult byteposition', 'copy copypartrequest', 'arraylist copypartresult', 'copypartrequest copyrequest', 'copypartrequest']\n",
      "Chunk 99 Keywords: ['s3client completemultipartupload', 's3client copypart', 'copyresponses s3client', 'multipart upload', 'completemultipartupload completerequest']\n",
      "Chunk 100 Keywords: ['s3 printstacktrace', 'parse response', 's3 amazons3clientbuilder', 's3 amazons3', 'amazonaws amazonserviceexception']\n",
      "Chunk 101 Keywords: ['partlisting s3client', 's3client listparts', 's3client amazons3clientbuilder', 'uploadid partlisting', 'amazons3 s3client']\n",
      "Chunk 102 Keywords: ['s3client amazons3clientbuilder', 's3 amazons3clientbuilder', 's3 printstacktrace', 'amazons3 s3client', 'bucket api']\n",
      "Chunk 103 Keywords: ['s3client listmultipartuploads', 'upload progress', 'multipartuploadlisting s3client', 'multipartuploadlisting getmultipartuploads', 'progress multipart']\n",
      "Chunk 104 Keywords: ['urls s3', 's3 printstacktrace', 'amazon s3', 'aws sdks', 'urls bucket']\n",
      "Chunk 105 Keywords: ['aws signature', 'aws identity', 'aws s3', 'stringequals s3', 'bucket object']\n",
      "Chunk 106 Keywords: ['restriction s3', 'access aws', 'aws speciﬁed', 'aws identity', 'notipaddressifexists aws']\n",
      "Chunk 107 Keywords: ['credentials aws', 'aws security', 'aws account', 'using aws', 'aws signature']\n",
      "Chunk 108 Keywords: ['using aws', 'aws sdks', 'sdks aws', 'updating bucket', 'amazon s3']\n",
      "Chunk 109 Keywords: ['urls s3', 'aws sdks', 's3 amazons3', 'cloud vpc', 'using aws']\n",
      "Chunk 110 Keywords: ['s3client amazons3clientbuilder', 'amazons3 s3client', 'amazons3clientbuilder', 'amazons3clientbuilder standard', 'url generatepresignedurlrequest']\n",
      "Chunk 111 Keywords: ['s3client generatepresignedurl', 'url s3client', 'urls s3', 'catch amazonserviceexception', 'amazonserviceexception transmitted']\n",
      "Chunk 112 Keywords: ['amazons3client bucketregion', 'bucketname accesspointarn', 'bucketregion regionendpoint', 'regionendpoint bucketregion', 'amazons3client']\n",
      "Chunk 113 Keywords: ['s3 generate_presigned_url', 'urlstring s3client', 's3client getpresignedurl', 'boto3 url', 'amazons3exception']\n",
      "Chunk 114 Keywords: ['python aws', 'aws command', 'updating bucket', 'creation aws', 'boto api']\n",
      "Chunk 115 Keywords: ['expires token', 'url expiration', 'urls s3', 'token expires', 'url expires']\n",
      "Chunk 116 Keywords: ['try putobjectrequest', 'putobjectpresignrequest', 'file presignedrequest', 'putobjectrequest', 'myurl presignedrequest']\n",
      "Chunk 117 Keywords: ['httpurlconnection', 'connection httpurlconnection', 'httpurlconnection connection', 'httpurlconnection url', 'guide httpurlconnection']\n",
      "Chunk 118 Keywords: ['s3_client boto3', 'generate_presigned_url s3_client', 's3_client generate_presigned_url', 'boto3 amazon', 'param s3_client']\n",
      "Chunk 119 Keywords: ['parse_args s3_client', 's3_client boto3', 's3 client_action', 's3_client client_action', 's3_client']\n",
      "Chunk 120 Keywords: ['data aws', 'aws data', 'amazon s3', 'aws process', 'hadoop s3a']\n",
      "Chunk 121 Keywords: ['aws sdk', 'creating s3', 'emr s3', 's3 outposts', 'amazon s3']\n",
      "Chunk 122 Keywords: ['abstractfilesystem s3a', 'abstractfilesystem s3', 'hadoop fs', 'apache hadoop', 'path s3a']\n",
      "Chunk 123 Keywords: ['aws s3', 'access s3', 'spark s3', 'arn aws', 's3 outposts']\n",
      "Chunk 124 Keywords: ['bucket accesspoint', 's3a bucket', 'aws s3', 'cluster enable', 's3a committer']\n",
      "Chunk 125 Keywords: ['clusters aws', 'subnet aws', 'aws outposts', 'ec2 instance', 's3a conﬁgurations']\n",
      "Chunk 126 Keywords: ['s3 outpostsexplanation', 's3a requires', 'outposts s3a', 'spark conﬁgurations', 's3 outposts']\n",
      "Chunk 127 Keywords: ['writes s3a', 's3a fileoutputcommitter', 'fileoutputcommitter s3', 's3 api', 'buckets s3a']\n",
      "Chunk 128 Keywords: ['aws sdks', 'aws api', 'aws sdk', 'cache s3', 'security aws']\n",
      "Chunk 129 Keywords: ['security aws', 'aws compliance', 'aws responsible', 'aws services', 'services aws']\n",
      "Chunk 130 Keywords: ['groups aws', 'bucket policies', 'policies bucket', 'policies s3', 'policies access']\n",
      "Chunk 131 Keywords: ['authorize s3', 'permissions s3', 'authorized s3', 'denied s3', 'api aws']\n",
      "Chunk 132 Keywords: ['aws gov', 'gov aws', 'regions aws', 'aws regions', 'aws region']\n",
      "Chunk 133 Keywords: ['outpost_idarn aws', 'outpost_id bucket', 'outpost_id accesspo', 'object_keyarn aws', 'outposts bucket']\n",
      "Chunk 134 Keywords: ['policies s3', 'bucket policy', 'principal aws', 'aws s3', 'aws action']\n",
      "Chunk 135 Keywords: ['permissions s3', 'endpoints s3', 'manage s3', 'aws resource', 'aws sourceip']\n",
      "Chunk 136 Keywords: ['ec2 describecoippools', 'describecoippools ec2', 'ec2 getcoippoolusage', 'ec2 describesecuritygroups', 'getcoippoolusage ec2']\n",
      "Chunk 137 Keywords: ['encryption aws', 'encryption amazon', 'encryption service', 'privately s3', 'server encryption']\n",
      "Chunk 138 Keywords: ['endpoints aws', 'routed s3', 'endpoint aws', 'accessing s3', 'endpoints s3']\n",
      "Chunk 139 Keywords: ['region vpce', 'aws region', 'vpce amazonaws', 'zonal dns', 'vpc endpoint']\n",
      "Chunk 140 Keywords: ['s3controlclient aws', 's3control region_name', 'accessing s3', 'api s3', 'service_name s3control']\n",
      "Chunk 141 Keywords: ['s3controlclient aws', 'endpoint aws', 'accessing s3', 'endpoint s3', 'endpoints s3']\n",
      "Chunk 142 Keywords: ['bucket vpc', 'access bucket', 'bucket access', 'bucket policies', 'bucket aws']\n",
      "Chunk 143 Keywords: ['endpoint aws', 'bucket vpce', 'bucket policies', 'aws sourcevpce', 'policies bucket']\n",
      "Chunk 144 Keywords: ['aws signature', 'bucket condition', 'bucket policy', 'stringequals aws', 'policies bucket']\n",
      "Chunk 145 Keywords: ['bucket signature', 'payloads signed', 'request signature', 'urls unsigned_payload', 'unsigned_payload information']\n",
      "Chunk 146 Keywords: ['bucket policy', 'aws s3', 'authtype rest', '01ac5d28a6a232904 bucket', 'bucket example']\n",
      "Chunk 147 Keywords: ['payloads uploads', 'payloads bucket', 'bucket policy', 'aws s3', 'uploads unsigned']\n",
      "Chunk 148 Keywords: ['policies aws', 'policies amazon', 'administered aws', 'aws managed', 'information aws']\n",
      "Chunk 149 Keywords: ['policies s3', 'role awsservicerolefors', 'policy awss3onoutpostsservicerolepolicy', 'awss3onoutpostsservicerolepolicy aws', 'aws services']\n",
      "Chunk 150 Keywords: ['permissions s3', 'roles aws', 'aws services', 'role s3', 'awsservicerolefors3onoutposts service']\n",
      "Chunk 151 Keywords: ['ec2 createnetworkinterface', 'permissions s3', 'createnetworkinterface resource', 'outposts api', 'sid createnetworkinterface']\n",
      "Chunk 152 Keywords: ['aws requesttag', 'stringequals aws', 'elastic ip', 'ec2 allocateaddress', 'ec2 elastic']\n",
      "Chunk 153 Keywords: ['ec2 createnetworkinterfacepermission', 'ec2 deletenetworkinterfacepermission', 'createnetworkinterfacepermission ec2', 'deletenetworkinterfacepermission ec2', 'permissions s3']\n",
      "Chunk 154 Keywords: ['ec2 createtags', 'ec2 createaction', 'aws requesttag', 'sid createtags', 'createtags resource']\n",
      "Chunk 155 Keywords: ['permissions s3', 'role s3', 'create s3', 'delete role', 'api s3']\n",
      "Chunk 156 Keywords: ['delete awsservicerolefors3onoutposts', 'awsservicerolefors3onoutposts role', 'deleting service', 'awsservicerolefors3onoutposts service', 'delete service']\n",
      "Chunk 157 Keywords: ['s3 versioning', 'versioning s3', 'managing s3', 'buckets versioning', 'versioning bucket']\n",
      "Chunk 158 Keywords: ['s3 versioning', 'versioning s3', 'managing s3', 'bucket versioning', 'aws management']\n",
      "Chunk 159 Keywords: ['versioning aws', 'versioning bucket', 's3control bucket', 's3 versioning', 'bucket versioning']\n",
      "Chunk 160 Keywords: ['s3 lifecycle', 'bucket lifecycle', 'aws management', 'lifecycle rule', 'buckets s3']\n",
      "Chunk 161 Keywords: ['versioning s3', 'bucket lifecycle', 's3 versioning', 'versions buckets', 'buckets s3']\n",
      "Chunk 162 Keywords: ['bucket lifecycle', 'lifecycle rule', 'versions buckets', 'deleting lifecycle', 'edit lifecycle']\n",
      "Chunk 163 Keywords: ['s3 lifecycle', 'bucket lifecycle', 'delete lifecycle', 'conﬁguration aws', 'aws sdk']\n",
      "Chunk 164 Keywords: ['mytagvalue2 key', 'mytagvalue1 key', 'mytagkey1 value', 'key mytagkey2', 'key mytagkey1']\n",
      "Chunk 165 Keywords: ['putbucketlifecycleconﬁguration amazon', 'putbucketlifecycleconﬁguration', 'information putbucketlifecycleconﬁguration', 'putbucketlifecycleconfiguration string', 'putbucketlifecycleconfiguration']\n",
      "Chunk 166 Keywords: ['lifecyclerulefilter withexpiration', 'lifecyclerulefilter', 'lifecyclerulefilter lifecyclerulefilter', 'lifecyclerulefilter withand', 'lifecyclerulefilter new']\n",
      "Chunk 167 Keywords: ['s3controlclient putbucketlifecycleconfiguration', 'bucketarn getbucketlifecycleconfigurationresult', 'bucketarn getbucketlifecycleconfigurationrequest', 'getbucketlifecycleconﬁguration', 'putbucketlifecycleconfiguration']\n",
      "Chunk 168 Keywords: ['s3 replication', 'replicate s3', 's3controlclient getbucketlifecycleconfiguration', 'replication aws', 'replication buckets']\n",
      "Chunk 169 Keywords: ['replicationconfiguration s3', 'replicationconfiguration role', 'permissions s3', 'replicationconfiguration', 'replication conﬁguration']\n",
      "Chunk 170 Keywords: ['s3 replication', 'replicationconﬁguration amazon', 'permissions s3', 'versioning s3', 's3 versioning']\n",
      "Chunk 171 Keywords: ['replication delete', 'replicate deletion', 'replicate delete', 's3 replica', 'replication bucket']\n",
      "Chunk 172 Keywords: ['s3 replication', 'bucket replication', 'updates bucket', 'supported s3', 's3 outposts']\n",
      "Chunk 173 Keywords: ['s3 replication', 'bucket replication', 'copyobject amazon', 'replicate objects', 'replicates objects']\n",
      "Chunk 174 Keywords: ['aws outposts', 'subnets replication', 'bucket replication', 'routing aws', 'creating replication']\n",
      "Chunk 175 Keywords: ['gateway aws', 'aws outposts', 'routing cidr', 'ipv4 pool', 'destination outpost']\n",
      "Chunk 176 Keywords: ['outpost subnet', 'subnet destination', 'choose subnets', 'choose subnet', 'enter subnet']\n",
      "Chunk 177 Keywords: ['create aws', 's3 outposts', 'resource s3', 'service s3', 'aws identity']\n",
      "Chunk 178 Keywords: ['replicateobject s3', 'behalf s3', 'bucket access', 'aws s3', 's3 outposts']\n",
      "Chunk 179 Keywords: ['permission s3', 'replicateobject s3', 'allow s3', 'permission replicates', 'aws s3']\n",
      "Chunk 180 Keywords: ['permissions s3', 'permission s3', 'permissions bucket', 'aws accounts', 'outposts replicateobject']\n",
      "Chunk 181 Keywords: ['principal aws', 'arn aws', 'aws s3', 'aws iam', 'aws arn']\n",
      "Chunk 182 Keywords: ['s3 replication', 's3 replicates', 'replicatedelete s3', 'aws s3', 'permission s3']\n",
      "Chunk 183 Keywords: ['bucket replication', 'replicating objects', 'replicated objects', 'replicate objects', 'buckets replicated']\n",
      "Chunk 184 Keywords: ['s3 replication', 'permission replicate', 'conﬁgure replication', 'replication api', 'replication rules']\n",
      "Chunk 185 Keywords: ['bucket replication', 'replication rule', 'ﬁltering replication', 'replication conﬁguration', 'setting replication']\n",
      "Chunk 186 Keywords: ['permission replicate', 'versioning bucket', 'outposts replication', 'permissions replication', 'replication permissions']\n",
      "Chunk 187 Keywords: ['s3 replicated', 'encryption s3', 'encryption aws', 's3 replica', 'replication conﬁguration']\n",
      "Chunk 188 Keywords: ['role aws', 'aws s3control', 'aws command', 'proﬁle aws', 'aws service']\n",
      "Chunk 189 Keywords: ['bucket versioning', 's3control bucket', 'aws s3control', 'bucket configuration', 'buckets aws']\n",
      "Chunk 190 Keywords: ['grants s3', 'service s3', 'service role', 'role replicationrole', 'role permissions']\n",
      "Chunk 191 Keywords: ['s3 outposts', 'outposts getobjectversiontagging', 'replicateobject s3', 'outposts replicatedelete', 'aws s3']\n",
      "Chunk 192 Keywords: ['replicationrolepolicy profile', 'replicationrole policy', 'bucket replication', 'aws s3control', 'policy replicationrolepolicy']\n",
      "Chunk 193 Keywords: ['s3control bucket', 'bucket replication', 'aws s3control', 'aws s3', 'retrieve replication']\n",
      "Chunk 194 Keywords: ['s3 replication', 'replication status', 'replication metrics', 'replication latency', 'troubleshooting replication']\n",
      "Chunk 195 Keywords: ['bucket replication', 's3 replica', 'replication status', 'replica s3', 'retry replication']\n",
      "Chunk 196 Keywords: ['replication s3', 'replica troubleshooting', 'troubleshooting replication', 'replication status', 'completed replication']\n",
      "Chunk 197 Keywords: ['bucket replication', 'replicateobject s3', 'replicatedelete s3', 'replicas bucket', 'buckets s3']\n",
      "Chunk 198 Keywords: ['s3 replication', 'eventbridge s3', 'amazon eventbridge', 'eventbridge notify', 'eventbridge amazon']\n",
      "Chunk 199 Keywords: ['s3 replication', 'eventbridge replication', 'dstbucketnotfound s3', 'dstmultipartinitnotpermitted s3', 'dstdelobjnotpermitted s3']\n",
      "Chunk 200 Keywords: ['replication s3', 'srcgettaggingnotpermitted s3', 'srcgetobjnotpermitted s3', 'srcbucketreplicationconfigmissing s3', 'dstputtaggingnotpermitted s3']\n",
      "Chunk 201 Keywords: ['eventbridge cloudwatch', 'cloudwatch logs', 'behavior cloudwatch', 'cloudwatch alarms', 'cloudwatch following']\n",
      "Chunk 202 Keywords: ['sharing aws', 'subnet s3', 'share aws', 'aws outposts', 's3 outposts']\n",
      "Chunk 203 Keywords: ['aws sdks', 'aws s3control', 'aws cli', 'user aws', 'aws account']\n",
      "Chunk 204 Keywords: ['aws s3api', 'endpoints aws', 'bucket1 vpc', 'object aws', 'aws s3']\n",
      "Chunk 205 Keywords: ['aws s3outposts', 's3 outpost', 's3 outposts', 'resource aws', 'aws outposts']\n",
      "Chunk 206 Keywords: ['monitoring s3', 's3 outposts', 'managing s3', 'outposts aws', 'outposts cloudwatch']\n",
      "Chunk 207 Keywords: ['s3 capacity', 's3 metrics', 's3 usage', 'metrics s3', 'cloudwatch metrics']\n",
      "Chunk 208 Keywords: ['s3 replication', 'amazon cloudwatch', 'targets cloudwatch', 'cloudwatch targets', 'cloudwatch events']\n",
      "Chunk 209 Keywords: ['monitoring s3', 'cloudwatch events', 'cloudtrail logs', 'cloudtrail eventsource', 'amazon cloudwatch']\n",
      "Chunk 210 Keywords: ['cloudtrail logging', 'logging s3', 'cloudtrail logs', 'logs aws', 'events aws']\n",
      "Chunk 211 Keywords: ['cloudtrail logging', 'logging cloudtrail', 'logging s3', 'events logging', 'log events']\n",
      "Chunk 212 Keywords: ['logging s3', 'cloudtrail logging', 'cloudtrail logs', 'log s3', 'cloudtrail log']\n",
      "Chunk 213 Keywords: ['cloudtrail log', 'parameters cloudtrail', 'shows cloudtrail', 'putobject awsregion', 'aws cli']\n",
      "Chunk 214 Keywords: ['cloudtrail log', 'aws cloudtrail', 'aes256 bucketname', 'bucketownerfullcontrol', 'objectcannedacl bucketownerfullcontrol']\n",
      "Chunk 215 Keywords: ['etag d41d8cd98f00b204e9800998ecf8427f', 'xohkitvzy1sulv1i6a52e0zox159fpfsityd58jhxwkxxaxi4iqkp6 signatureversion', 'requestid 8e96d972160306fa', 'ciphersuite ecdhe', 'authheader requestid']\n",
      "Chunk 216 Keywords: ['s3 apis', 'aws cloudtrail', 'aws s3', 's3 outposts', 'cloudtrail log']\n",
      "Chunk 217 Keywords: ['s3 api', 'aws management', 'conﬁgure s3', 'aws sdks', 's3 outposts']\n",
      "Chunk 218 Keywords: ['putbucketversioning s3', 'createbucket amazon', 'buckets api', 'managing buckets', 'outposts api']\n",
      "Chunk 219 Keywords: ['accessing s3', 'ipv6 aws', 'conﬁguring s3', 'requests s3', 'bucket ipv6']\n",
      "Chunk 220 Keywords: ['bucket ipv6', 'ipv6 api', 'outposts ipv6', 'endpoints aws', 'addresses ipv6']\n",
      "Chunk 221 Keywords: ['bucket ipv6', 'prevents ipv6', 'bucket policies', 'bucket policy', 'handle ipv6']\n",
      "Chunk 222 Keywords: ['ipaddress aws', 'allow ipv6', 'aws sourceip', 'endpoint ipv6', 'organization ipv6']\n",
      "Chunk 223 Keywords: ['ipv6 aws', 'endpoint ipv6', 'dig s3', 'endpoints aws', 'vpc ipv6']\n",
      "Chunk 224 Keywords: ['vpc endpoints', 'vpc endpoint', 'multiple subnets', 'selected subnets', 'subnets availability']\n",
      "Chunk 225 Keywords: ['endpoint aws', 'ipv6 aws', 'aws cli', 'vpc endpoint', 'networks aws']\n",
      "Chunk 226 Keywords: ['aws privatelink', 'endpoints aws', 'bucket ipv6', 'buckets ipv6', 'outposts ipv6']\n",
      "Chunk 227 Keywords: ['s3api aws', 's3outposts aws', 'aws endpoint', 'endpoint aws', 'endpoints aws']\n",
      "Chunk 228 Keywords: ['s3controlexception', 's3controlexception public', 'model s3controlexception', 'services s3control', 'create s3controlclient']\n",
      "Chunk 229 Keywords: ['s3controlclient listregionalbuckets', 'listbuckets s3controlclient', 'listregionalbucketsrequest listregionalbucketsrequest', 'listregionalbucketsrequest', 'listregionalbuckets listregionalbucketsrequest']\n",
      "Chunk 230 Keywords: ['catch s3controlexception', 's3outpostsexception public', 's3outpostsexception', 's3controlexception using', 'services s3outposts']\n",
      "Chunk 231 Keywords: ['s3outpostsclient listendpoints', 'listendpoints s3outpostsclient', 's3outpostsexception', 'catch s3outpostsexception', 's3outpostsclient']\n",
      "Chunk 232 Keywords: ['catch s3outpostsexception', 's3outpostsexception unknown', 's3outpostsexception', 'sdkclientexception amazon', 'printstacktrace catch']\n"
     ]
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "# Initialize KeyBERT for keyword extraction\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Step 1: Extract keywords for each chunk\n",
    "chunk_keywords = {}\n",
    "for i, chunk in enumerate(chunks):\n",
    "    keywords = kw_model.extract_keywords(chunk, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=5)\n",
    "    chunk_keywords[i] = [kw[0] for kw in keywords]\n",
    "\n",
    "# Step 2: Group similar keywords or tag chunks\n",
    "for chunk_id, keywords in chunk_keywords.items():\n",
    "    print(f\"Chunk {chunk_id} Keywords: {keywords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f39cb1",
   "metadata": {},
   "source": [
    "## Sanity check of Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7641d5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of chunks (in characters): 1722.59\n",
      "Average number of tokens per chunk: 448.86\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Frequent Keywords Across All Chunks:\n",
      "s3 outposts: 40\n",
      "aws s3: 34\n",
      "aws s3control: 16\n",
      "aws outposts: 15\n",
      "aws management: 13\n",
      "aws sdks: 12\n",
      "using aws: 12\n",
      "accessing s3: 11\n",
      "s3 apis: 11\n",
      "permissions s3: 10\n",
      "\n",
      "Summary Statistics:\n",
      "       Chunk Length  Token Count\n",
      "count    233.000000   233.000000\n",
      "mean    1722.587983   448.858369\n",
      "std      627.776929    77.860627\n",
      "min      619.000000   165.000000\n",
      "25%     1372.000000   418.000000\n",
      "50%     1748.000000   482.000000\n",
      "75%     1970.000000   511.000000\n",
      "max     6090.000000   512.000000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Calculate the average length of chunks (in characters)\n",
    "chunk_lengths = [len(chunk) for chunk in chunks]\n",
    "average_length = np.mean(chunk_lengths)\n",
    "print(f\"Average length of chunks (in characters): {average_length:.2f}\")\n",
    "\n",
    "# Step 2: Calculate the average number of tokens per chunk using the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")  # Or any other tokenizer you've been using\n",
    "chunk_token_counts = [len(tokenizer.encode(chunk, truncation=True)) for chunk in chunks]\n",
    "average_token_count = np.mean(chunk_token_counts)\n",
    "print(f\"Average number of tokens per chunk: {average_token_count:.2f}\")\n",
    "\n",
    "# Step 3: Create a DataFrame from chunk lengths for analysis\n",
    "df_chunks = pd.DataFrame({'Chunk Length': chunk_lengths, 'Token Count': chunk_token_counts})\n",
    "\n",
    "# Step 4: Plot histograms of chunk length and token count distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Histogram for chunk lengths\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df_chunks['Chunk Length'], bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Chunk Lengths (Characters)\")\n",
    "plt.xlabel(\"Length (Characters)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "# Histogram for token counts\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_chunks['Token Count'], bins=30, color='lightgreen', edgecolor='black')\n",
    "plt.title(\"Distribution of Token Counts\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Analyze keyword frequency across chunks\n",
    "from collections import Counter\n",
    "\n",
    "all_keywords = [kw for kws in chunk_keywords.values() for kw in kws]\n",
    "keyword_frequency = Counter(all_keywords)\n",
    "\n",
    "print(\"\\nTop 10 Most Frequent Keywords Across All Chunks:\")\n",
    "for kw, freq in keyword_frequency.most_common(10):\n",
    "    print(f\"{kw}: {freq}\")\n",
    "\n",
    "# Step 6: Print statistics summary\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df_chunks.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45984075",
   "metadata": {},
   "source": [
    "## Chunking by index(contents of PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "828372fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from each page of the PDF.\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = [page.extract_text() for page in reader.pages]\n",
    "    return text\n",
    "\n",
    "def parse_index(index_text):\n",
    "    \"\"\"Parses the index to identify section titles and page numbers.\"\"\"\n",
    "    index_pattern = re.compile(r'^(.*)\\s+(\\d+)$')\n",
    "    sections = []\n",
    "    \n",
    "    for line in index_text.splitlines():\n",
    "        match = index_pattern.match(line)\n",
    "        if match:\n",
    "            section_title, page_number = match.groups()\n",
    "            sections.append({\n",
    "                \"title\": section_title.strip(),\n",
    "                \"start_page\": int(page_number)\n",
    "            })\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def create_chunks(text_by_page, sections):\n",
    "    \"\"\"Creates chunks by mapping sections from the index to content.\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    for i, section in enumerate(sections):\n",
    "        start_page = section['start_page'] - 1\n",
    "        end_page = sections[i + 1]['start_page'] - 1 if i + 1 < len(sections) else len(text_by_page)\n",
    "        content = \" \".join(text_by_page[start_page:end_page])\n",
    "        chunks.append({\n",
    "            \"title\": section['title'],\n",
    "            \"content\": content\n",
    "        })\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e6b2c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_text = \"\"\"\n",
    "\n",
    "What is S3 on Outposts? ................................................................................................................. 1\n",
    "How S3 on Outposts works ....................................................................................................................... 1\n",
    "Regions ...................................................................................................................................................... 2\n",
    "Buckets ....................................................................................................................................................... 2\n",
    "Objects ....................................................................................................................................................... 3\n",
    "Keys ............................................................................................................................................................ 3\n",
    "S3 Versioning ........................................................................................................................................... 4\n",
    "Version ID .................................................................................................................................................. 4\n",
    "Storage class and encryption ............................................................................................................... 4\n",
    "Bucket policy ............................................................................................................................................ 4\n",
    "S3 on Outposts access points .............................................................................................................. 5\n",
    "Features of S3 on Outposts ....................................................................................................................... 5\n",
    "Access management ............................................................................................................................... 5\n",
    "Storage logging and monitoring ......................................................................................................... 6\n",
    "Strong consistency .................................................................................................................................. 6\n",
    "Related services ............................................................................................................................................ 7\n",
    "Accessing S3 on Outposts .......................................................................................................................... 7\n",
    "AWS Management Console ................................................................................................................... 7\n",
    "AWS Command Line Interface ............................................................................................................. 7\n",
    "AWS SDKs ................................................................................................................................................. 8\n",
    "Paying for S3 on Outposts ......................................................................................................................... 8\n",
    "Next steps ...................................................................................................................................................... 8\n",
    "Setting up your Outpost ............................................................................................................... 10\n",
    "Order a new Outpost ................................................................................................................................ 10\n",
    "How S3 on Outposts is diﬀerent .................................................................................................. 11\n",
    "Specifications .............................................................................................................................................. 11\n",
    "Supported API operations ........................................................................................................................ 12\n",
    "Unsupported Amazon S3 features ......................................................................................................... 12\n",
    "Network restrictions .................................................................................................................................. 13\n",
    "Getting started with S3 on Outposts ........................................................................................... 14\n",
    "Using the S3 console ................................................................................................................................ 14\n",
    "Create a bucket, an access point, and an endpoint ....................................................................... 15\n",
    "Next steps ............................................................................................................................................... 17\n",
    "Using the AWS CLI and SDK for Java .................................................................................................... 17\n",
    "API Version 2006-03-01 iii\n",
    "Amazon S3 on Outposts User Guide\n",
    "Step 1: Create a bucket ....................................................................................................................... 18\n",
    "Step 2: Create an access point ........................................................................................................... 19\n",
    "Step 3: Create an endpoint ................................................................................................................ 20\n",
    "Step 4: Upload an object to an S3 on Outposts bucket ............................................................... 22\n",
    "Networking for S3 on Outposts ................................................................................................... 23\n",
    "Choosing your networking access type ................................................................................................. 23\n",
    "Accessing your S3 on Outposts buckets and objects ......................................................................... 23\n",
    "Managing connections using cross-account elastic network interfaces .......................................... 24\n",
    "Working with S3 on Outposts buckets ........................................................................................ 25\n",
    "Buckets ......................................................................................................................................................... 25\n",
    "Access points ............................................................................................................................................... 25\n",
    "Endpoints ..................................................................................................................................................... 26\n",
    "API operations on S3 on Outposts ......................................................................................................... 26\n",
    "Creating and managing S3 on Outposts buckets ................................................................................ 28\n",
    "Creating a bucket ....................................................................................................................................... 28\n",
    "Adding tags ................................................................................................................................................. 32\n",
    "Using bucket policies ................................................................................................................................. 33\n",
    "Adding a bucket policy ........................................................................................................................ 34\n",
    "Viewing a bucket policy ...................................................................................................................... 36\n",
    "Deleting a bucket policy ..................................................................................................................... 37\n",
    "Bucket policy examples ....................................................................................................................... 38\n",
    "Listing buckets ............................................................................................................................................ 42\n",
    "Getting a bucket ......................................................................................................................................... 43\n",
    "Deleting your bucket ................................................................................................................................. 45\n",
    "Working with access points ..................................................................................................................... 46\n",
    "Creating an access point ..................................................................................................................... 47\n",
    "Using a bucket-style alias for your access point ............................................................................ 48\n",
    "Viewing access point configuration .................................................................................................. 53\n",
    "Listing access points ............................................................................................................................. 54\n",
    "Deleting an access point ..................................................................................................................... 55\n",
    "Adding an access point policy ............................................................................................................ 56\n",
    "Viewing an access point policy .......................................................................................................... 58\n",
    "Working with endpoints ........................................................................................................................... 59\n",
    "Creating an endpoint ........................................................................................................................... 60\n",
    "Listing endpoints .................................................................................................................................. 62\n",
    "Deleting an endpoint ........................................................................................................................... 64\n",
    "API Version 2006-03-01 iv\n",
    "Amazon S3 on Outposts User Guide\n",
    "Working with S3 on Outposts objects ......................................................................................... 66\n",
    "Upload an object ........................................................................................................................................ 67\n",
    "Copying an object ...................................................................................................................................... 69\n",
    "Using the AWS SDK for Java .............................................................................................................. 70\n",
    "Getting an object ....................................................................................................................................... 71\n",
    "Listing objects ............................................................................................................................................. 74\n",
    "Deleting objects .......................................................................................................................................... 77\n",
    "Using HeadBucket ...................................................................................................................................... 81\n",
    "Performing a multipart upload ............................................................................................................... 83\n",
    "Perform a multipart upload of an object in an S3 on Outposts bucket .................................... 84\n",
    "Copy a large object in an S3 on Outposts bucket by using multipart upload .......................... 86\n",
    "List parts of an object in an S3 on Outposts bucket .................................................................... 88\n",
    "Retrieve a list of in-progress multipart uploads in an S3 on Outposts bucket ......................... 90\n",
    "Using presigned URLs ............................................................................................................................... 91\n",
    "Limiting presigned URL capabilities .................................................................................................. 91\n",
    "Who can create a presigned URL ...................................................................................................... 93\n",
    "When does S3 on Outposts check the expiration date and time of a presigned URL? ............ 94\n",
    "Sharing objects ...................................................................................................................................... 94\n",
    "Uploading an object ............................................................................................................................. 99\n",
    "Amazon S3 on Outposts with local Amazon EMR ............................................................................ 104\n",
    "Creating an Amazon S3 on Outposts bucket ............................................................................... 105\n",
    "Getting started using Amazon EMR with Amazon S3 on Outposts ......................................... 106\n",
    "Authorization and authentication caching ......................................................................................... 111\n",
    "Configuring the authorization and authentication cache .......................................................... 112\n",
    "Validating SigV4A signing ................................................................................................................ 112\n",
    "Security ........................................................................................................................................ 113\n",
    "Setting up IAM ......................................................................................................................................... 113\n",
    "Principals for S3 on Outposts policies ........................................................................................... 116\n",
    "ARNs for S3 on Outposts ................................................................................................................. 116\n",
    "Example policies for S3 on Outposts ............................................................................................. 118\n",
    "Permissions for endpoints ................................................................................................................ 119\n",
    "Service-linked roles for S3 on Outposts ........................................................................................ 121\n",
    "Data encryption ........................................................................................................................................ 121\n",
    "AWS PrivateLink for S3 on Outposts .................................................................................................. 122\n",
    "Restrictions and limitations .............................................................................................................. 123\n",
    "Accessing S3 on Outposts interface endpoints ............................................................................ 124\n",
    "API Version 2006-03-01 v\n",
    "Amazon S3 on Outposts User Guide\n",
    "Updating an on-premises DNS configuration ............................................................................... 126\n",
    "Creating a VPC endpoint .................................................................................................................. 126\n",
    "Creating VPC endpoint policies and bucket policies ................................................................... 126\n",
    "Signature Version 4 (SigV4) policy keys ............................................................................................. 128\n",
    "Bucket policy examples that use Signature Version 4-related condition keys ....................... 130\n",
    "AWS managed policies ........................................................................................................................... 132\n",
    "AWSS3OnOutpostsServiceRolePolicy ............................................................................................. 132\n",
    "Policy updates ..................................................................................................................................... 133\n",
    "Using service-linked roles ...................................................................................................................... 133\n",
    "Service-linked role permissions for S3 on Outposts ................................................................... 134\n",
    "Creating a service-linked role for S3 on Outposts ...................................................................... 137\n",
    "Editing a service-linked role for S3 on Outposts ......................................................................... 137\n",
    "Deleting a service-linked role for S3 on Outposts ...................................................................... 137\n",
    "Supported Regions for S3 on Outposts service-linked roles ..................................................... 138\n",
    "Managing S3 on Outposts storage ............................................................................................. 139\n",
    "Managing S3 Versioning ......................................................................................................................... 139\n",
    "Creating and managing a lifecycle configuration ............................................................................. 141\n",
    "Using the console ............................................................................................................................... 142\n",
    "Using the AWS CLI and SDK for Java ............................................................................................. 145\n",
    "Replicating objects for S3 on Outposts .............................................................................................. 149\n",
    "Replication configuration .................................................................................................................. 150\n",
    "Requirements for S3 Replication on Outposts ............................................................................. 151\n",
    "What is replicated? ............................................................................................................................. 152\n",
    "What isn't replicated? ........................................................................................................................ 152\n",
    "What isn't supported by S3 Replication on Outposts? ............................................................... 153\n",
    "Setting up replication ........................................................................................................................ 153\n",
    "Managing your replication ................................................................................................................ 172\n",
    "Sharing S3 on Outposts ......................................................................................................................... 180\n",
    "Prerequisites ........................................................................................................................................ 180\n",
    "Procedure .............................................................................................................................................. 181\n",
    "Usage examples .................................................................................................................................. 182\n",
    "Other services ........................................................................................................................................... 184\n",
    "Monitoring S3 on Outposts ........................................................................................................ 186\n",
    "CloudWatch metrics ................................................................................................................................ 186\n",
    "CloudWatch metrics ........................................................................................................................... 187\n",
    "Amazon CloudWatch Events .................................................................................................................. 188\n",
    "API Version 2006-03-01 vi\n",
    "Amazon S3 on Outposts User Guide\n",
    "CloudTrail logs .......................................................................................................................................... 190\n",
    "Enabling CloudTrail logging for S3 on Outposts objects ........................................................... 190\n",
    "Amazon S3 on Outposts AWS CloudTrail log file entries ........................................................... 193\n",
    "Developing with S3 on Outposts ................................................................................................ 196\n",
    "S3 on Outposts APIs ............................................................................................................................... 196\n",
    "Amazon S3 API operations for managing objects ....................................................................... 196\n",
    "Amazon S3 Control API operations for managing buckets ....................................................... 197\n",
    "S3 on Outposts API operations for managing Outposts ............................................................ 198\n",
    "Configuring S3 control client ................................................................................................................ 199\n",
    "Making requests over IPv6 ..................................................................................................................... 199\n",
    "Getting started with IPv6 ................................................................................................................. 200\n",
    "Making requests using dual-stack endpoints ............................................................................... 201\n",
    "Using IPv6 addresses in IAM policies ............................................................................................. 201\n",
    "Testing IP address compatibility ..................................................................................................... 202\n",
    "Using IPv6 with AWS PrivateLink .................................................................................................... 203\n",
    "Using dual-stack endpoints .............................................................................................................. 206\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e30c315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "pdfname = 's3-outposts'\n",
    "pdf_path = f'{pdfname}.pdf'\n",
    "\n",
    "# Extract and parse\n",
    "text_by_page = extract_text_from_pdf(pdf_path)\n",
    "sections = parse_index(index_text)\n",
    "chunks = create_chunks(text_by_page, sections)\n",
    "\n",
    "# Save chunks to JSON\n",
    "with open(f\"{pdfname}_chunks.json\", \"w\") as f:\n",
    "    json.dump(chunks, f, indent=4)\n",
    "    \n",
    "print(\"Chunks created and saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26a3e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The JSON file contains a list with 158 items.\n",
      "\n",
      "Unique headers found: 2\n",
      "- title\n",
      "- content\n",
      "\n",
      "Detailed statistics for each header:\n",
      "- title:\n",
      "  * Average length: 137.34\n",
      "  * Sample data type: str\n",
      "  * Sample value: What is S3 on Outposts? .................................................................................................................\n",
      "\n",
      "- content:\n",
      "  * Average length: 2471.72\n",
      "  * Sample data type: str\n",
      "\n",
      "\n",
      "Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check for chunking\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "\n",
    "def analyze_json(file_path):\n",
    "    \"\"\"Reads a JSON file and prints out detailed statistics on its structure and key lengths.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        if isinstance(data, list):\n",
    "            print(f\"The JSON file contains a list with {len(data)} items.\\n\")\n",
    "            \n",
    "            # Identify unique headers and their types\n",
    "            headers = set()\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    headers.update(item.keys())\n",
    "            \n",
    "            print(f\"Unique headers found: {len(headers)}\")\n",
    "            for header in headers:\n",
    "                print(f\"- {header}\")\n",
    "            \n",
    "            # Gather statistics on each header\n",
    "            header_stats = defaultdict(list)\n",
    "            for item in data:\n",
    "                for header in headers:\n",
    "                    if header in item:\n",
    "                        header_stats[header].append(len(str(item[header])))\n",
    "                    else:\n",
    "                        header_stats[header].append(0)\n",
    "            \n",
    "            # Print average length and data type information\n",
    "            print(\"\\nDetailed statistics for each header:\")\n",
    "            for header, lengths in header_stats.items():\n",
    "                avg_length = mean(lengths)\n",
    "                sample_value = next((item[header] for item in data if header in item), None)\n",
    "                value_type = type(sample_value).__name__ if sample_value is not None else \"NoneType\"\n",
    "                print(f\"- {header}:\")\n",
    "                print(f\"  * Average length: {avg_length:.2f}\")\n",
    "                print(f\"  * Sample data type: {value_type}\")\n",
    "                if sample_value:\n",
    "                    print(f\"  * Sample value: {sample_value}\")\n",
    "                print(\"\")\n",
    "\n",
    "        elif isinstance(data, dict):\n",
    "            print(\"The JSON file contains a dictionary with the following keys:\")\n",
    "            for key, value in data.items():\n",
    "                value_type = type(value).__name__\n",
    "                print(f\"- {key}:\")\n",
    "                print(f\"  * Data type: {value_type}\")\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    print(f\"  * Length: {len(value)}\")\n",
    "                print(\"\")\n",
    "\n",
    "        else:\n",
    "            print(\"The JSON file contains a single item of an unrecognized structure.\")\n",
    "\n",
    "        print(\"\\nAnalysis complete.\")\n",
    "\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(\"Failed to read the file due to encoding error:\", e)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = f\"{pdfname}_chunks.json\"  # Replace with your file path\n",
    "analyze_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c65f6109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks with keywords saved successfully to s3-outposts_chunks_with_keywords.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# Load the chunks from the JSON file created in the previous step\n",
    "pdfname = 's3-outposts'\n",
    "input_file_path = f\"{pdfname}_chunks.json\"\n",
    "output_file_path = f\"{pdfname}_chunks_with_keywords.json\"\n",
    "\n",
    "# Step 1: Load the JSON file containing the chunks\n",
    "with open(input_file_path, \"r\") as file:\n",
    "    chunks = json.load(file)\n",
    "\n",
    "# Step 2: Initialize KeyBERT for keyword extraction\n",
    "kw_model = KeyBERT()\n",
    "\n",
    "# Step 3: Extract keywords for each chunk\n",
    "for chunk in chunks:\n",
    "    content = chunk[\"content\"]\n",
    "    \n",
    "    # Extract keywords\n",
    "    keywords = kw_model.extract_keywords(\n",
    "        content, \n",
    "        keyphrase_ngram_range=(1, 2), \n",
    "        stop_words='english', \n",
    "        top_n=5\n",
    "    )\n",
    "    chunk[\"keywords\"] = [kw[0] for kw in keywords]  # Store extracted keywords in each chunk\n",
    "\n",
    "# Step 4: Save the new JSON file with title, keywords, and content for each chunk\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(chunks, f, indent=4)\n",
    "\n",
    "print(f\"Chunks with keywords saved successfully to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dda27",
   "metadata": {},
   "source": [
    "## Embedd to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67804b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import tiktoken  # Ensure tiktoken is installed if used for chunk tokenization\n",
    "\n",
    "# Initialize Pinecone\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"llm-chatbot-project\"  # Change if desired\n",
    "\n",
    "# Delete existing index if dimension mismatch\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name in existing_indexes:\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# Create index with the correct dimension (384 for avsolatorio/NoInstruct-small-Embedding-v0)\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    ")\n",
    "\n",
    "# Wait until the index is ready\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "\n",
    "# Re-initialize the index after creation\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acb1d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0de57527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# Assuming `model` and `tokenizer` are already loaded (e.g., SentenceTransformer, T5, etc.)\n",
    "\n",
    "# Function to compute embeddings\n",
    "def get_embedding(text, mode=\"sentence\"):\n",
    "    model.eval()\n",
    "    inp = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**inp)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()  # [CLS] token representation\n",
    "\n",
    "# Function to index semantic chunks and metadata in Pinecone\n",
    "def index_chunks_with_metadata(index, chunks_with_metadata):\n",
    "    # Process each chunk, compute embeddings, and store it in Pinecone\n",
    "    for i, chunk_data in enumerate(chunks_with_metadata):\n",
    "        # Extract the content and metadata\n",
    "        chunk = chunk_data[\"content\"]\n",
    "        keywords = chunk_data.get(\"keywords\", [])\n",
    "        title = chunk_data.get(\"title\", \"Unknown Title\")\n",
    "\n",
    "        # Generate embedding for the chunk\n",
    "        embedding = get_embedding(chunk).flatten().tolist()\n",
    "\n",
    "        # Prepare metadata for Pinecone\n",
    "        doc_metadata = {\n",
    "            \"title\": title,\n",
    "            \"keywords\": keywords,\n",
    "            \"text\": chunk  # Storing the text as part of metadata if desired\n",
    "        }\n",
    "\n",
    "        # Index each chunk in Pinecone\n",
    "        index.upsert(\n",
    "            [(f\"chunk-{i}\", embedding, doc_metadata)]\n",
    "        )\n",
    "\n",
    "        # Print progress every 100 chunks\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Indexed {i + 1} chunks out of {len(chunks_with_metadata)}\")\n",
    "\n",
    "    print(\"All chunks and metadata have been successfully indexed in Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7afee403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 100 chunks out of 158\n",
      "All chunks and metadata have been successfully indexed in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load chunks with metadata from JSON file\n",
    "with open(\"s3-outposts_chunks_with_keywords.json\", \"r\") as file:\n",
    "    chunks_with_metadata = json.load(file)\n",
    "\n",
    "# Index the chunks with metadata\n",
    "# Note: The `index` variable should be the Pinecone index instance that you have already created\n",
    "index_chunks_with_metadata(index, chunks_with_metadata)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "716e72a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: chunk-32\n",
      "Text (truncated to 500 characters): \n",
      "\n",
      "Metadata:\n",
      "{'keywords': [], 'text': '', 'title': 'Next steps ...............................................................................................................................................'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID: chunk-31\n",
      "Text (truncated to 500 characters): Amazon S3 on Outposts User Guide\n",
      "The AWS Command Line Interface (AWS CLI) provides commands for a broad set of AWS services. \n",
      "The AWS CLI is supported on Windows, macOS, and Linux. To get started, see the AWS Command \n",
      "Line Interface User Guide. For more information about the commands that you can use with S3 on \n",
      "Outposts, see s3api , s3control, and s3outposts  in the AWS CLI Command Reference.\n",
      "AWS SDKs\n",
      "AWS provides SDKs (software development kits) that consist of libraries and sample code for \n",
      "v\n",
      "\n",
      "Metadata:\n",
      "{'keywords': ['s3 apis', 'aws s3', 'managing s3', 'aws services', 'services aws'], 'text': 'Amazon S3 on Outposts User Guide\\nThe AWS Command Line Interface (AWS CLI) provides commands for a broad set of AWS services. \\nThe AWS CLI is supported on Windows, macOS, and Linux. To get started, see the AWS Command \\nLine Interface User Guide. For more information about the commands that you can use with S3 on \\nOutposts, see s3api , s3control, and s3outposts  in the AWS CLI Command Reference.\\nAWS SDKs\\nAWS provides SDKs (software development kits) that consist of libraries and sample code for \\nvarious programming languages and platforms (Java, Python, Ruby, .NET, iOS, Android, and so \\non). The AWS SDKs provide a convenient way to create programmatic access to S3 on Outposts \\nand AWS. Because S3 on Outposts uses the same SDKs as Amazon S3, S3 on Outposts provides a \\nconsistent experience using the same S3 APIs, automation, and tools.\\nS3 on Outposts is a REST service. You can send requests to S3 on Outposts by using the AWS SDK \\nlibraries, which wrap the underlying REST API and simplify your programming tasks. For example, \\nthe SDKs take care of tasks such as calculating signatures, cryptographically signing requests, \\nmanaging errors, and retrying requests automatically. For information about the AWS SDKs, \\nincluding how to download and install them, see Tools to Build on AWS.\\nPaying for S3 on Outposts\\nYou can purchase a variety of AWS Outposts rack conﬁgurations featuring a combination of \\nAmazon EC2 instance types, Amazon EBS General Purpose solid state drive (SSD) volumes (gp2), \\nand S3 on Outposts. Pricing includes delivery, installation, infrastructure service maintenance, and \\nsoftware patches and upgrades.\\nFor more information, see AWS Outposts rack pricing.\\nNext steps\\nFor more information about working with S3 on Outposts, see the following topics:\\n•Setting up your Outpost\\n•How is Amazon S3 on Outposts diﬀerent from Amazon S3?\\n•Getting started with Amazon S3 on Outposts\\n•Networking for S3 on Outposts\\n•Working with S3 on Outposts buckets\\nAWS SDKs API Version 2006-03-01 8 Amazon S3 on Outposts User Guide\\n•Working with S3 on Outposts objects\\n•Security in S3 on Outposts\\n•Managing S3 on Outposts storage\\n•Developing with Amazon S3 on Outposts\\nNext steps API Version 2006-03-01 9', 'title': 'Create a bucket, an access point, and an endpoint .......................................................................'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID: chunk-30\n",
      "Text (truncated to 500 characters): Amazon S3 on Outposts User Guide\n",
      "Related services\n",
      "After you load your data into S3 on Outposts, you can use it with other AWS services. The following \n",
      "are the services that you might use most frequently:\n",
      "•Amazon Elastic Compute Cloud (Amazon EC2) – Provides secure and scalable computing capacity \n",
      "in the AWS Cloud. Using Amazon EC2 lessens your need to invest in hardware up front, so you \n",
      "can develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few \n",
      "virtual serve\n",
      "\n",
      "Metadata:\n",
      "{'keywords': ['aws services', 'aws cloud', 'use aws', 's3 aws', 'aws management'], 'text': \"Amazon S3 on Outposts User Guide\\nRelated services\\nAfter you load your data into S3 on Outposts, you can use it with other AWS services. The following \\nare the services that you might use most frequently:\\n•Amazon Elastic Compute Cloud (Amazon EC2) – Provides secure and scalable computing capacity \\nin the AWS Cloud. Using Amazon EC2 lessens your need to invest in hardware up front, so you \\ncan develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few \\nvirtual servers as you need, conﬁgure security and networking, and manage storage.\\n•Amazon Elastic Block Store (Amazon EBS) on Outposts – Use Amazon EBS local snapshots on \\nOutposts to store snapshots of volumes on an Outpost locally in S3 on Outposts.\\n•Amazon Relational Database Service (Amazon RDS) on Outposts – Use Amazon RDS local \\nbackups to store your Amazon RDS backups locally on your Outpost.\\n•AWS DataSync – Automate transferring data between your Outposts and AWS Regions, choosing \\nwhat to transfer, when to transfer, and how much network bandwidth to use. S3 on Outposts is \\nintegrated with AWS DataSync. For on-premises applications that require high-throughput local \\nprocessing, S3 on Outposts provides on-premises object storage to minimize data transfers and \\nbuﬀer from network variations, while providing you the ability to easily transfer data between \\nOutposts and AWS Regions.\\nAccessing S3 on Outposts\\nYou can work with S3 on Outposts in any of the following ways:\\nAWS Management Console\\nThe console is a web-based user interface for managing S3 on Outposts and AWS resources. If \\nyou've signed up for an AWS account, you can access S3 on Outposts by signing into the AWS \\nManagement Console and choosing S3 from the AWS Management Console home page. Then, \\nchoose Outposts buckets from the left navigation pane.\\nAWS Command Line Interface\\nYou can use the AWS command line tools to issue commands or build scripts at your system's \\ncommand line to perform AWS (including S3) tasks.\\nRelated services API Version 2006-03-01 7\", 'title': 'Using the S3 console ................................................................................................................................'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID: chunk-33\n",
      "Text (truncated to 500 characters): Amazon S3 on Outposts User Guide\n",
      "Setting up your Outpost\n",
      "To get started with Amazon S3 on Outposts, you will need an Outpost with Amazon S3 capacity \n",
      "deployed at your facility. For information about options for ordering an Outpost and S3 \n",
      "capacity, see AWS Outposts. To check if your Outposts has S3 capacity on it, you can use the\n",
      "ListOutpostsWithS3  API call. For speciﬁcations and to see how S3 on Outposts is diﬀerent than \n",
      "Amazon S3, see How is Amazon S3 on Outposts diﬀerent from Amazon S3?\n",
      "For\n",
      "\n",
      "Metadata:\n",
      "{'keywords': ['s3 outposts', 'outposts s3', 'outpost s3', 'aws outposts', 'outpost capacity'], 'text': 'Amazon S3 on Outposts User Guide\\nSetting up your Outpost\\nTo get started with Amazon S3 on Outposts, you will need an Outpost with Amazon S3 capacity \\ndeployed at your facility. For information about options for ordering an Outpost and S3 \\ncapacity, see AWS Outposts. To check if your Outposts has S3 capacity on it, you can use the\\nListOutpostsWithS3  API call. For speciﬁcations and to see how S3 on Outposts is diﬀerent than \\nAmazon S3, see How is Amazon S3 on Outposts diﬀerent from Amazon S3?\\nFor more information, see the following topics.\\nTopics\\n•Order a new Outpost\\nOrder a new Outpost\\nIf you need to order a new Outpost with S3 capacity, see AWS Outposts rack pricing to understand \\nthe capacity options for Amazon Elastic Compute Cloud (Amazon EC2), Amazon Elastic Block Store \\n(Amazon EBS), and Amazon S3.\\nAfter you select your conﬁguration, follow the steps in Create an Outpost and order Outpost \\ncapacity in the AWS Outposts User Guide.\\nOrder a new Outpost API Version 2006-03-01 10', 'title': 'Using the AWS CLI and SDK for Java ....................................................................................................'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ID: chunk-34\n",
      "Text (truncated to 500 characters): Amazon S3 on Outposts User Guide\n",
      "How is Amazon S3 on Outposts diﬀerent from Amazon \n",
      "S3?\n",
      "Amazon S3 on Outposts delivers object storage to your on-premises AWS Outposts environment. \n",
      "Using S3 on Outposts helps you to meet local processing, data residency, and demanding \n",
      "performance needs by keeping data close to on-premises applications. Because it uses Amazon \n",
      "S3 APIs and features, S3 on Outposts makes it easy to store, secure, tag, report on, and control \n",
      "access to the data on your Outposts and \n",
      "\n",
      "Metadata:\n",
      "{'keywords': ['aws outposts', 's3 outposts', 'outposts s3', 'aws infrastructure', 'outposts storage'], 'text': 'Amazon S3 on Outposts User Guide\\nHow is Amazon S3 on Outposts diﬀerent from Amazon \\nS3?\\nAmazon S3 on Outposts delivers object storage to your on-premises AWS Outposts environment. \\nUsing S3 on Outposts helps you to meet local processing, data residency, and demanding \\nperformance needs by keeping data close to on-premises applications. Because it uses Amazon \\nS3 APIs and features, S3 on Outposts makes it easy to store, secure, tag, report on, and control \\naccess to the data on your Outposts and extend AWS infrastructure to your on-premises facility for \\na consistent hybrid experience.\\nFor more information about how S3 on Outposts is unique, see the following topics.\\nTopics\\n•S3 on Outposts speciﬁcations\\n•API operations supported by S3 on Outposts\\n•Amazon S3 features not supported by S3 on Outposts\\n•S3 on Outposts network requirements\\nS3 on Outposts speciﬁcations\\n•The maximum Outposts bucket size is 50 TB.\\n•The maximum number of Outposts buckets is 100 per AWS account.\\n•Outposts buckets can be accessed only by using access points and endpoints.\\n•The maximum number of access points per Outposts bucket is 10.\\n•Access point policies are limited to 20 KB in size.\\n•The Outpost owner can manage access within your organization in AWS Organizations by using \\nAWS Resource Access Manager. All accounts that need access to the Outpost must be within the \\nsame organization as the owner account in AWS Organizations.\\n•The S3 on Outposts bucket owner account is always the owner of all objects in the bucket.\\n•Only the S3 on Outposts bucket owner account can perform operations on the bucket.\\n•Object size limitations are consistent with Amazon S3.\\n•All objects stored on S3 on Outposts are stored in the OUTPOSTS  storage class.\\nSpeciﬁcations API Version 2006-03-01 11', 'title': 'Step 1: Create a bucket .......................................................................................................................'}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Total number of chunks: 158\n",
      "Average length of chunks: 2471.72 characters\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Fetch some sample chunks from the index\n",
    "# Assume that we upserted data with ids in the format \"chunk-0\", \"chunk-1\", etc.\n",
    "num_samples = 5  # Number of samples to fetch\n",
    "sample_ids = [f\"chunk-{i}\" for i in range(30,35)]\n",
    "response = index.fetch(ids=sample_ids)\n",
    "\n",
    "# Step 2: Extract the chunks and metadata\n",
    "sample_chunks = []\n",
    "for item_id, item_data in response['vectors'].items():\n",
    "    chunk_text = item_data['metadata'].get('text', '')\n",
    "    sample_chunks.append(chunk_text)\n",
    "    print(f\"ID: {item_id}\")\n",
    "    print(f\"Text (truncated to 500 characters): {chunk_text[:500]}\")\n",
    "    print(\"\\nMetadata:\")\n",
    "    print(item_data['metadata'])\n",
    "    print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "\n",
    "# Step 3: Compute Statistics for Chunk Lengths\n",
    "# Fetch all metadata for the sanity check\n",
    "fetch_response = index.describe_index_stats()\n",
    "total_chunks = fetch_response['total_vector_count']\n",
    "\n",
    "# Fetch chunks by iterating over index ids\n",
    "# Assuming chunks are indexed as \"chunk-0\" to \"chunk-(total_chunks-1)\"\n",
    "all_chunk_lengths = []\n",
    "batch_size = 100  # Process chunks in batches to avoid overloading the system\n",
    "for i in range(0, total_chunks, batch_size):\n",
    "    ids = [f\"chunk-{j}\" for j in range(i, min(i + batch_size, total_chunks))]\n",
    "    response = index.fetch(ids=ids)\n",
    "    for item_data in response['vectors'].values():\n",
    "        chunk_text = item_data['metadata'].get('text', '')\n",
    "        all_chunk_lengths.append(len(chunk_text))\n",
    "\n",
    "# Compute average length of chunks\n",
    "average_length = np.mean(all_chunk_lengths)\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Total number of chunks: {total_chunks}\")\n",
    "print(f\"Average length of chunks: {average_length:.2f} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6b4af",
   "metadata": {},
   "source": [
    "## Integrate LLM with chain and chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8ebc05d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7e93c5aac341f3a8ef1554a74f4877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42051dd40e244b94aa775edc78ed35d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336e8e3dffb242bc9a175752482e1c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a67cbbc9c94dd8a7f205c71db47f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c5c5f4d6434b5081ad516f3f4d98b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index 'llm-chatbot-project' in Pinecone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/0cvsl7fj6nzdpcfzc69z4gz00000gn/T/ipykernel_73564/3163501024.py:70: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 0.3.0. Use :class:`~PineconeVectorStore` instead.\n",
      "  vectorstore = LangchainPinecone(index=index, embedding=embedding)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import Pinecone as LangchainPinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Optional, List\n",
    "\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "# Initialize Vertex AI for Google Gemini model\n",
    "PROJECT_ID = \"ids-560-project-group-1-bosch\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Custom wrapper for Google Gemini to make it compatible with LangChain\n",
    "class RunnableGemini(LLM):\n",
    "    def __init__(self, model: GenerativeModel):\n",
    "        super().__init__()\n",
    "        self._model = model\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        response = self._model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"google_gemini\"\n",
    "\n",
    "# Instantiate the wrapped model\n",
    "llm = RunnableGemini(gemini_model)\n",
    "\n",
    "# Load the embedding model for the retriever function\n",
    "MODEL_NAME = \"avsolatorio/NoInstruct-small-Embedding-v0\"\n",
    "embedding_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "embedding_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Custom LangChain Embedding wrapper\n",
    "class HFEmbeddingWrapper(Embeddings):\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return get_embedding(text).flatten().tolist()\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [get_embedding(text).flatten().tolist() for text in texts]\n",
    "\n",
    "# Initialize the custom embedding wrapper\n",
    "embedding = HFEmbeddingWrapper()\n",
    "\n",
    "# Initialize Pinecone client\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\") or input(\"Enter your Pinecone API key: \")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"llm-chatbot-project\"\n",
    "\n",
    "# Check if the index exists; if not, create it with dimension 384\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to index '{index_name}' in Pinecone.\")\n",
    "\n",
    "# Initialize LangChain Pinecone Retriever with embedding wrapper\n",
    "vectorstore = LangchainPinecone(index=index, embedding=embedding)\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Define the QA PromptTemplate for debugging and documentation assistance\n",
    "QA_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an expert code debugger and documentation assistant. Help answer technical queries based on the script provided, offering solutions, clarifications, or steps as needed. Use precise language and avoid assumptions. Refer to the documentation context for direct responses.\n",
    "\n",
    "Documentation Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Set up the conversational retrieval chain with the custom Gemini wrapper\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    condense_question_prompt=QA_PROMPT,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_PROMPT},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Function to maintain conversation history in the RAG chain\n",
    "def ask_question_with_history(qa_chain, question, chat_history):\n",
    "    result = qa_chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
    "    print(\"Response:\", result[\"answer\"])\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    return chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0bd809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/0cvsl7fj6nzdpcfzc69z4gz00000gn/T/ipykernel_73564/4113032440.py:31: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
      "/var/folders/07/0cvsl7fj6nzdpcfzc69z4gz00000gn/T/ipykernel_73564/4113032440.py:45: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain(inputs)\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     53\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the steps to create a bucket, access point, and endpoint for Amazon S3 on Outposts?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 54\u001b[0m memory \u001b[38;5;241m=\u001b[39m ask_question_with_history(qa_chain, question, memory)\n\u001b[1;32m     56\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan you explain how Amazon S3 on Outposts is different from regular Amazon S3?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m memory \u001b[38;5;241m=\u001b[39m ask_question_with_history(qa_chain, question, memory)\n",
      "Cell \u001b[0;32mIn[74], line 45\u001b[0m, in \u001b[0;36mask_question_with_history\u001b[0;34m(qa_chain, question, memory)\u001b[0m\n\u001b[1;32m     39\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,  \u001b[38;5;66;03m# Use 'question' as the key\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m: chat_history,\n\u001b[1;32m     42\u001b[0m }\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Call the QA chain with the inputs\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m qa_chain(inputs)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Display the result and update memory\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    390\u001b[0m     inputs,\n\u001b[1;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/retrieval_qa/base.py:154\u001b[0m, in \u001b[0;36mBaseRetrievalQA._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_docs(question)  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_documents_chain\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    155\u001b[0m     input_documents\u001b[38;5;241m=\u001b[39mdocs, question\u001b[38;5;241m=\u001b[39mquestion, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child()\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_source_documents:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key: answer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m: docs}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:611\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    607\u001b[0m         _output_key\n\u001b[1;32m    608\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    612\u001b[0m         _output_key\n\u001b[1;32m    613\u001b[0m     ]\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    618\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but none were provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    619\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    390\u001b[0m     inputs,\n\u001b[1;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/combine_documents/base.py:138\u001b[0m, in \u001b[0;36mBaseCombineDocumentsChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001b[39;00m\n\u001b[1;32m    137\u001b[0m other_keys \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_key}\n\u001b[0;32m--> 138\u001b[0m output, extra_return_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombine_docs(\n\u001b[1;32m    139\u001b[0m     docs, callbacks\u001b[38;5;241m=\u001b[39m_run_manager\u001b[38;5;241m.\u001b[39mget_child(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mother_keys\n\u001b[1;32m    140\u001b[0m )\n\u001b[1;32m    141\u001b[0m extra_return_dict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key] \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extra_return_dict\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/combine_documents/stuff.py:259\u001b[0m, in \u001b[0;36mStuffDocumentsChain.combine_docs\u001b[0;34m(self, docs, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_inputs(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Call predict on the LLM.\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs), {}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:318\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[1;32m    390\u001b[0m     inputs,\n\u001b[1;32m    391\u001b[0m     cast(RunnableConfig, {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}),\n\u001b[1;32m    392\u001b[0m     return_only_outputs\u001b[38;5;241m=\u001b[39mreturn_only_outputs,\n\u001b[1;32m    393\u001b[0m     include_run_info\u001b[38;5;241m=\u001b[39minclude_run_info,\n\u001b[1;32m    394\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:126\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    123\u001b[0m     inputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    124\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 126\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate([inputs], run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/chains/llm.py:138\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    139\u001b[0m         prompts,\n\u001b[1;32m    140\u001b[0m         stop,\n\u001b[1;32m    141\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs,\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    146\u001b[0m         cast(List, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    147\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:755\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    749\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    754\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m     ]\n\u001b[0;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[1;32m    951\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    952\u001b[0m     )\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 779\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[1;32m    780\u001b[0m                 prompts,\n\u001b[1;32m    781\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    782\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[1;32m    783\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    784\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    785\u001b[0m             )\n\u001b[1;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1504\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1501\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1502\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1503\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m-> 1504\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1505\u001b[0m     )\n\u001b[1;32m   1506\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "Cell \u001b[0;32mIn[73], line 27\u001b[0m, in \u001b[0;36mRunnableGemini._call\u001b[0;34m(self, prompt, stop)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:654\u001b[0m, in \u001b[0;36m_GenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels, stream)\u001b[0m\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content_streaming(\n\u001b[1;32m    646\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    647\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_content(\n\u001b[1;32m    655\u001b[0m         contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    656\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[1;32m    657\u001b[0m         safety_settings\u001b[38;5;241m=\u001b[39msafety_settings,\n\u001b[1;32m    658\u001b[0m         tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    659\u001b[0m         tool_config\u001b[38;5;241m=\u001b[39mtool_config,\n\u001b[1;32m    660\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    661\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:779\u001b[0m, in \u001b[0;36m_GenerativeModel._generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, tools, tool_config, labels)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates content.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[1;32m    754\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03m    A single GenerationResponse object\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    771\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[1;32m    772\u001b[0m     contents\u001b[38;5;241m=\u001b[39mcontents,\n\u001b[1;32m    773\u001b[0m     generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    777\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m    778\u001b[0m )\n\u001b[0;32m--> 779\u001b[0m gapic_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client\u001b[38;5;241m.\u001b[39mgenerate_content(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_response(gapic_response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/vertexai/generative_models/_generative_models.py:3138\u001b[0m, in \u001b[0;36mGenerativeModel._prediction_client\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prediction_client\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m prediction_service_v1\u001b[38;5;241m.\u001b[39mPredictionServiceClient:\n\u001b[1;32m   3135\u001b[0m     \u001b[38;5;66;03m# Switch to @functools.cached_property once its available.\u001b[39;00m\n\u001b[1;32m   3136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prediction_client_value\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   3137\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 3138\u001b[0m             aiplatform_initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mcreate_client(\n\u001b[1;32m   3139\u001b[0m                 client_class\u001b[38;5;241m=\u001b[39mprediction_service_v1\u001b[38;5;241m.\u001b[39mPredictionServiceClient,\n\u001b[1;32m   3140\u001b[0m                 location_override\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_location,\n\u001b[1;32m   3141\u001b[0m                 prediction_client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   3142\u001b[0m             )\n\u001b[1;32m   3143\u001b[0m         )\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prediction_client_value\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/cloud/aiplatform/initializer.py:591\u001b[0m, in \u001b[0;36m_Config.create_client\u001b[0;34m(self, client_class, credentials, location_override, prediction_client, api_base_path_override, api_key, api_path_override, appended_user_agent, appended_gapic_version)\u001b[0m\n\u001b[1;32m    583\u001b[0m     user_agent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_agent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(appended_user_agent)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m client_info \u001b[38;5;241m=\u001b[39m gapic_v1\u001b[38;5;241m.\u001b[39mclient_info\u001b[38;5;241m.\u001b[39mClientInfo(\n\u001b[1;32m    586\u001b[0m     gapic_version\u001b[38;5;241m=\u001b[39mgapic_version,\n\u001b[1;32m    587\u001b[0m     user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    588\u001b[0m )\n\u001b[1;32m    590\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredentials\u001b[39m\u001b[38;5;124m\"\u001b[39m: credentials \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcredentials,\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_client_options(\n\u001b[1;32m    593\u001b[0m         location_override\u001b[38;5;241m=\u001b[39mlocation_override,\n\u001b[1;32m    594\u001b[0m         prediction_client\u001b[38;5;241m=\u001b[39mprediction_client,\n\u001b[1;32m    595\u001b[0m         api_key\u001b[38;5;241m=\u001b[39mapi_key,\n\u001b[1;32m    596\u001b[0m         api_base_path_override\u001b[38;5;241m=\u001b[39mapi_base_path_override,\n\u001b[1;32m    597\u001b[0m         api_path_override\u001b[38;5;241m=\u001b[39mapi_path_override,\n\u001b[1;32m    598\u001b[0m     ),\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: client_info,\n\u001b[1;32m    600\u001b[0m }\n\u001b[1;32m    602\u001b[0m \u001b[38;5;66;03m# Do not pass \"grpc\", rely on gapic defaults unless \"rest\" is specified\u001b[39;00m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_transport \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrest\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsync\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m client_class\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;66;03m# User requests async rest\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/cloud/aiplatform/initializer.py:392\u001b[0m, in \u001b[0;36m_Config.credentials\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m logging_warning_filter \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mLoggingFilter(logging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[1;32m    391\u001b[0m logger\u001b[38;5;241m.\u001b[39maddFilter(logging_warning_filter)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_project_as_env_var_or_google_auth_default()\n\u001b[1;32m    393\u001b[0m credentials \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials\n\u001b[1;32m    394\u001b[0m logger\u001b[38;5;241m.\u001b[39mremoveFilter(logging_warning_filter)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/cloud/aiplatform/initializer.py:117\u001b[0m, in \u001b[0;36m_Config._set_project_as_env_var_or_google_auth_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project \u001b[38;5;241m=\u001b[39m project\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key:\n\u001b[0;32m--> 117\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mdefault()\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_credentials \u001b[38;5;241m=\u001b[39m credentials\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/google/auth/_default.py:693\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    685\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    686\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    687\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    689\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    690\u001b[0m             )\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 693\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Your default credentials were not found. To set up Application Default Credentials, see https://cloud.google.com/docs/authentication/external/set-up-adc for more information."
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Define the QA PromptTemplate with the 'context' and 'question' placeholders\n",
    "QA_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "You are an assistant helping with error debugging and code understanding. Use the context provided to answer the user's question. If there is no context, let the user know more information is needed.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User's Question: {question}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "# Initialize your LLM and retriever (already defined in your environment)\n",
    "\n",
    "# Create the RetrievalQA chain with the custom prompt and specify the input key\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"question\",  # Specify 'question' as the input key\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": QA_PROMPT,\n",
    "    },\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# Initialize memory to store conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"question\")\n",
    "\n",
    "# Function to ask a question with context management\n",
    "def ask_question_with_history(qa_chain, question, memory):\n",
    "    # Retrieve the conversation history\n",
    "    chat_history = memory.load_memory_variables({}).get(\"chat_history\", \"\")\n",
    "\n",
    "    # Prepare the inputs\n",
    "    inputs = {\n",
    "        \"question\": question,  # Use 'question' as the key\n",
    "        \"chat_history\": chat_history,\n",
    "    }\n",
    "\n",
    "    # Call the QA chain with the inputs\n",
    "    result = qa_chain(inputs)\n",
    "\n",
    "    # Display the result and update memory\n",
    "    print(\"Response:\", result[\"result\"])\n",
    "    memory.save_context({\"question\": question}, {\"result\": result[\"result\"]})\n",
    "    return memory\n",
    "\n",
    "# Example usage\n",
    "question = \"What are the steps to create a bucket, access point, and endpoint for Amazon S3 on Outposts?\"\n",
    "memory = ask_question_with_history(qa_chain, question, memory)\n",
    "\n",
    "question = \"Can you explain how Amazon S3 on Outposts is different from regular Amazon S3?\"\n",
    "memory = ask_question_with_history(qa_chain, question, memory)\n",
    "\n",
    "question = \"What are the supported API operations for Amazon S3 on Outposts, and how do they differ from standard Amazon S3?\"\n",
    "memory = ask_question_with_history(qa_chain, question, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e917ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
